{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"code_8_BGRU_attention.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"SQoEzO-1eML0","colab_type":"code","outputId":"f048fbc4-9e3b-45a2-f722-622bf71d32db","executionInfo":{"status":"ok","timestamp":1560250732318,"user_tz":-120,"elapsed":2120,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split, KFold\n","import random\n","\n","from sklearn.model_selection import cross_validate\n","from sklearn.metrics import roc_auc_score, average_precision_score\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","from keras.preprocessing import text, sequence\n","from keras.layers import Embedding, SpatialDropout1D\n","from keras.models import Model, Sequential\n","from keras.layers import Dense, Embedding, Input\n","from keras.optimizers import RMSprop\n","import keras.backend as K\n","from keras.layers import Dense, Input, GRU, LSTM, Bidirectional, Dropout, CuDNNLSTM, CuDNNGRU, GlobalAveragePooling1D, GlobalMaxPool1D\n","from sklearn.metrics import average_precision_score, roc_auc_score\n","from sklearn.model_selection import StratifiedKFold\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras.engine.topology import Layer, InputSpec\n","from keras import initializers as initializers, regularizers, constraints\n","\n","from numpy.random import seed\n","from tensorflow import set_random_seed\n","import random as rn\n","import os"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qCeSyw_eCrx4","colab_type":"code","outputId":"5a0e22c7-2998-433c-d359-1814028a8d19","executionInfo":{"status":"ok","timestamp":1560250732320,"user_tz":-120,"elapsed":1663,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# GOOGLE COLAB SETUP\n","\n","# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nak1uhxiEK0R","colab_type":"code","colab":{}},"source":["#2. Get the file\n","data_path          = 'drive/My Drive/Colab Notebooks/adaptHAN/AOBDL_code/data'\n","codes_path         = 'drive/My Drive/Colab Notebooks/adaptHAN/AOBDL_code/codes'\n","cv_models_path     = 'drive/My Drive/Colab Notebooks/adaptHAN/AOBDL_code/cv_models'\n","models_path        = 'drive/My Drive/Colab Notebooks/adaptHAN/AOBDL_code/models'\n","\n","\n","#3. Read file as panda dataframe\n","train         = pd.read_csv(f'{data_path}/train_cleaned_no_punkt.csv') \n","test_labelled = pd.read_csv(f'{data_path}/test_labelled_cleaned_no_punkt.csv') \n","test_unlabelled = pd.read_csv(f'{data_path}/test_unlabelled_cleaned_no_punkt.csv') "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f3ZeAcM_eGpj","colab_type":"code","colab":{}},"source":["train['mal']         = train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) >= 1  \n","train.drop(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'], axis=1, inplace=True)\n","train.comment_text.fillna(\"empty\", inplace=True)\n","\n","test_labelled['mal'] = test_labelled[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) >= 1  \n","test_labelled.drop(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'], axis=1, inplace=True)\n","test_labelled.comment_text.fillna(\"empty\", inplace=True)\n","\n","test_unlabelled.comment_text.fillna(\"empty\", inplace=True)\n","\n","# CHANGE TRAIN AND TEST, MIX TO GET SIMILAR DISTRIBUTION\n","from sklearn.model_selection import train_test_split\n","rs=42\n","X_train1, X_test1, y_train1, y_test1  = train_test_split(train.drop('mal', axis=1), train.mal, stratify=train.mal, test_size=0.29, random_state=rs )\n","X_train2, X_test2, y_train2, y_test2  = train_test_split(test_labelled.drop('mal', axis=1), test_labelled.mal, stratify=test_labelled.mal, test_size=0.29, random_state=rs)\n","\n","X = np.concatenate((X_train1.comment_text, X_train2.comment_text))\n","y = np.concatenate((y_train1, y_train2))\n","\n","X_test = np.concatenate((X_test1.comment_text, X_test2.comment_text))\n","y_test = np.concatenate((y_test1, y_test2))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pWPSaXneFFZu","colab_type":"code","colab":{}},"source":["#X = train.comment_text\n","#y = train.mal\n","\n","max_features = 40000\n","maxlen       = 400\n","dropout_rate = 0.25\n","rs           = 42\n","epochs       = 4\n","batch_size   = 256\n","embed_dim    = 50\n","rec_units    = 150\n","\n","\n","\n","\n","seed(rs)\n","set_random_seed(rs)\n","rn.seed(rs)\n","\n","os.environ['PYTHONHASHSEED']=str(rs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4DPm1-btWNGB","colab_type":"code","colab":{}},"source":["def dot_product(x, kernel):\n","    if K.backend() == 'tensorflow':\n","        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n","    else:\n","        return K.dot(x, kernel)\n","\n","class AttentionWithContext(Layer):\n","    def __init__(self,\n","                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n","                 W_constraint=None, u_constraint=None, b_constraint=None,\n","                 bias=True, **kwargs):\n","\n","        self.supports_masking = True\n","        self.init = initializers.get('glorot_uniform')\n","\n","        self.W_regularizer = regularizers.get(W_regularizer)\n","        self.u_regularizer = regularizers.get(u_regularizer)\n","        self.b_regularizer = regularizers.get(b_regularizer)\n","\n","        self.W_constraint = constraints.get(W_constraint)\n","        self.u_constraint = constraints.get(u_constraint)\n","        self.b_constraint = constraints.get(b_constraint)\n","\n","        self.bias = bias\n","        super(AttentionWithContext, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 3\n","\n","        self.W = self.add_weight((input_shape[-1], input_shape[-1]),\n","                                 initializer=self.init,\n","                                 name='{}_W'.format(self.name),\n","                                 regularizer=self.W_regularizer,\n","                                 constraint=self.W_constraint)\n","        if self.bias:\n","            self.b = self.add_weight((input_shape[-1],),\n","                                     initializer='zero',\n","                                     name='{}_b'.format(self.name),\n","                                     regularizer=self.b_regularizer,\n","                                     constraint=self.b_constraint)\n","\n","        self.u = self.add_weight((input_shape[-1],),\n","                                 initializer=self.init,\n","                                 name='{}_u'.format(self.name),\n","                                 regularizer=self.u_regularizer,\n","                                 constraint=self.u_constraint)\n","\n","        super(AttentionWithContext, self).build(input_shape)\n","\n","    def compute_mask(self, input, input_mask=None):\n","        return None\n","\n","    def call(self, x, mask=None):\n","        uit = dot_product(x, self.W)\n","\n","        if self.bias:\n","            uit += self.b\n","\n","        uit = K.tanh(uit)\n","        ait = dot_product(uit, self.u)\n","\n","        a = K.exp(ait)\n","\n","        if mask is not None:\n","            # Cast the mask to floatX to avoid float64 upcasting in theano\n","            a *= K.cast(mask, K.floatx())\n","\n","        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n","\n","        a = K.expand_dims(a)\n","        weighted_input = x * a\n","        return K.sum(weighted_input, axis=1)\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape[0], input_shape[-1]\n","      \n","      \n","      \n","class AttLayer(Layer):\n","    def __init__(self, attention_dim):\n","        self.init = initializers.get('normal')\n","        self.supports_masking = True\n","        self.attention_dim = attention_dim\n","        super(AttLayer, self).__init__()\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 3\n","        self.W = K.variable(self.init((input_shape[-1], self.attention_dim)))\n","        self.b = K.variable(self.init((self.attention_dim, )))\n","        self.u = K.variable(self.init((self.attention_dim, 1)))\n","        self.trainable_weights = [self.W, self.b, self.u]\n","        super(AttLayer, self).build(input_shape)\n","\n","    def compute_mask(self, inputs, mask=None):\n","        return mask\n","\n","    def call(self, x, mask=None):\n","        # size of x :[batch_size, sel_len, attention_dim]\n","        # size of u :[batch_size, attention_dim]\n","        # uit = tanh(xW+b)\n","        uit = K.tanh(K.bias_add(K.dot(x, self.W), self.b))\n","        ait = K.dot(uit, self.u)\n","        ait = K.squeeze(ait, -1)\n","\n","        ait = K.exp(ait)\n","\n","        if mask is not None:\n","            # Cast the mask to floatX to avoid float64 upcasting in theano\n","            ait *= K.cast(mask, K.floatx())\n","        ait /= K.cast(K.sum(ait, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n","        ait = K.expand_dims(ait)\n","        weighted_input = x * ait\n","        output = K.sum(weighted_input, axis=1)\n","\n","        return output\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0], input_shape[-1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ac0ThFO3FIHI","colab_type":"code","colab":{}},"source":["def gru_keras(max_features, maxlen, dropout_rate, embed_dim, rec_units, reduction = 'average'):\n","    if K.backend == 'tensorflow':        \n","        K.clear_session()\n","    input_layer = Input(shape=(maxlen,))\n","    embedding_layer = Embedding(max_features, output_dim=embed_dim, trainable=True)(input_layer)\n","    x = SpatialDropout1D(dropout_rate)(embedding_layer)\n","    x = Bidirectional(CuDNNGRU(units=rec_units, return_sequences=True))(x)\n","    if reduction == 'average':\n","      x = GlobalAveragePooling1D()(x)\n","    elif reduction == 'maximum':\n","      x = GlobalMaxPool1D()(x)\n","    elif reduction == 'attention':\n","      x = AttentionWithContext()(x)\n","      \n","    output_layer = Dense(1, activation=\"sigmoid\")(x)\n","    model = Model(inputs=input_layer, outputs=output_layer)\n","    model.compile(loss='binary_crossentropy',\n","                  optimizer=RMSprop(clipvalue=1, clipnorm=1),\n","                  metrics=['acc'])\n","    #print( model.summary())\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BFgVXjNPF-dM","colab_type":"code","colab":{}},"source":["kf = StratifiedKFold(n_splits=5, random_state=rs)\n","auc = []\n","roc = []\n","c = 0\n","tokenizer = text.Tokenizer(num_words=max_features)\n","tokenizer.fit_on_texts(X)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jjvUHMVYj3qv","colab_type":"text"},"source":["### Average Pooling"]},{"cell_type":"code","metadata":{"id":"-49hvW4_GHww","colab_type":"code","outputId":"3d487fbb-34de-4f1d-8334-53d788c188de","executionInfo":{"status":"ok","timestamp":1560252016517,"user_tz":-120,"elapsed":1278171,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":1474}},"source":["for train_index, val_index in kf.split(X, y):\n","    print(f' fold {c}')\n","    X_train, X_val       = X[train_index], X[val_index]\n","    y_train, y_val       = y[train_index], y[val_index] \n","    #tokenizer = text.Tokenizer(num_words=max_features)\n","    #tokenizer.fit_on_texts(pd.concat([X_train, unlab.comment_text], axis=0))\n","    list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n","    list_tokenized_val   = tokenizer.texts_to_sequences(X_val)\n","    X_train              = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n","    X_val                = sequence.pad_sequences(list_tokenized_val, maxlen=maxlen)\n","    model                = gru_keras(max_features, maxlen, dropout_rate, embed_dim, rec_units)\n","    print('Fitting')\n","    history              = model.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val), epochs=4, shuffle=False, verbose=1)\n","    probs                = model.predict(X_val, batch_size=batch_size, verbose=1)\n","    \n","    model.save_weights(f'{cv_models_path}/BGRU_avpool_fold_{c}.h5')\n","    \n","    auc_f                = average_precision_score(y_val, probs)\n","    auc.append(auc_f)\n","    roc_f                = roc_auc_score(y_val, probs)\n","    roc.append(roc_f)\n","    print(f' average precision {auc_f}')\n","    print(f' roc auc {roc_f}')\n","    c += 1\n","    del model"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" fold 0\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","Fitting\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Train on 126974 samples, validate on 31745 samples\n","Epoch 1/4\n","126974/126974 [==============================] - 61s 482us/step - loss: 0.2689 - acc: 0.9101 - val_loss: 0.1472 - val_acc: 0.9549\n","Epoch 2/4\n","126974/126974 [==============================] - 60s 471us/step - loss: 0.1395 - acc: 0.9521 - val_loss: 0.1495 - val_acc: 0.9495\n","Epoch 3/4\n","126974/126974 [==============================] - 60s 469us/step - loss: 0.1423 - acc: 0.9522 - val_loss: 0.1480 - val_acc: 0.9484\n","Epoch 4/4\n","126974/126974 [==============================] - 60s 471us/step - loss: 0.1132 - acc: 0.9591 - val_loss: 0.1547 - val_acc: 0.9476\n","31745/31745 [==============================] - 5s 151us/step\n"," average precision 0.8852375041267283\n"," roc auc 0.9688102934579501\n"," fold 1\n","Fitting\n","Train on 126974 samples, validate on 31745 samples\n","Epoch 1/4\n","126974/126974 [==============================] - 61s 477us/step - loss: 0.2505 - acc: 0.9165 - val_loss: 0.1752 - val_acc: 0.9486\n","Epoch 2/4\n","126974/126974 [==============================] - 59s 468us/step - loss: 0.1622 - acc: 0.9435 - val_loss: 0.1710 - val_acc: 0.9468\n","Epoch 3/4\n","126974/126974 [==============================] - 60s 470us/step - loss: 0.1732 - acc: 0.9316 - val_loss: 0.1510 - val_acc: 0.9472\n","Epoch 4/4\n","126974/126974 [==============================] - 60s 469us/step - loss: 0.1070 - acc: 0.9588 - val_loss: 0.1536 - val_acc: 0.9482\n","31745/31745 [==============================] - 5s 153us/step\n"," average precision 0.8845889655344565\n"," roc auc 0.9698129624348195\n"," fold 2\n","Fitting\n","Train on 126976 samples, validate on 31743 samples\n","Epoch 1/4\n","126976/126976 [==============================] - 60s 476us/step - loss: 0.2488 - acc: 0.9178 - val_loss: 0.1822 - val_acc: 0.9466\n","Epoch 2/4\n","126976/126976 [==============================] - 59s 466us/step - loss: 0.1427 - acc: 0.9523 - val_loss: 0.1661 - val_acc: 0.9493\n","Epoch 3/4\n","126976/126976 [==============================] - 59s 467us/step - loss: 0.1738 - acc: 0.9404 - val_loss: 0.1487 - val_acc: 0.9477\n","Epoch 4/4\n","126976/126976 [==============================] - 59s 467us/step - loss: 0.1059 - acc: 0.9596 - val_loss: 0.1534 - val_acc: 0.9493\n","31743/31743 [==============================] - 5s 154us/step\n"," average precision 0.888002069789456\n"," roc auc 0.9697771410522169\n"," fold 3\n","Fitting\n","Train on 126976 samples, validate on 31743 samples\n","Epoch 1/4\n","126976/126976 [==============================] - 60s 476us/step - loss: 0.2524 - acc: 0.9187 - val_loss: 0.2056 - val_acc: 0.9399\n","Epoch 2/4\n","126976/126976 [==============================] - 59s 467us/step - loss: 0.2161 - acc: 0.9401 - val_loss: 0.1708 - val_acc: 0.9404\n","Epoch 3/4\n","126976/126976 [==============================] - 59s 468us/step - loss: 0.1312 - acc: 0.9567 - val_loss: 0.1588 - val_acc: 0.9404\n","Epoch 4/4\n","126976/126976 [==============================] - 59s 468us/step - loss: 0.1189 - acc: 0.9586 - val_loss: 0.1464 - val_acc: 0.9429\n","31743/31743 [==============================] - 5s 155us/step\n"," average precision 0.8245702442628984\n"," roc auc 0.9649157146798557\n"," fold 4\n","Fitting\n","Train on 126976 samples, validate on 31743 samples\n","Epoch 1/4\n","126976/126976 [==============================] - 61s 478us/step - loss: 0.2413 - acc: 0.9221 - val_loss: 0.4402 - val_acc: 0.9038\n","Epoch 2/4\n","126976/126976 [==============================] - 59s 466us/step - loss: 0.1347 - acc: 0.9542 - val_loss: 0.3171 - val_acc: 0.9041\n","Epoch 3/4\n","126976/126976 [==============================] - 59s 467us/step - loss: 0.1062 - acc: 0.9611 - val_loss: 0.2513 - val_acc: 0.9108\n","Epoch 4/4\n","126976/126976 [==============================] - 59s 468us/step - loss: 0.0957 - acc: 0.9645 - val_loss: 0.2449 - val_acc: 0.9158\n","31743/31743 [==============================] - 5s 156us/step\n"," average precision 0.7774732950976063\n"," roc auc 0.965669584154507\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oD-G2cO9GLz3","colab_type":"code","colab":{}},"source":["data = pd.DataFrame({'acc':history.history['acc'],\n","                    'loss': history.history['loss'],\n","                    'val_acc': history.history['val_acc'],\n","                    'val_loss': history.history['val_loss']})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S51--4EBjMKx","colab_type":"code","outputId":"f9f0f21e-a5d6-4357-9049-431045cd6adc","executionInfo":{"status":"ok","timestamp":1560252016526,"user_tz":-120,"elapsed":1265584,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["np.array(auc).mean()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8519744157622291"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"EPtxc1qPTfoC","colab_type":"code","outputId":"74de6cd4-0658-4a92-fbb5-4b16dc1eee21","executionInfo":{"status":"ok","timestamp":1560252016527,"user_tz":-120,"elapsed":1264643,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["np.array(roc).mean()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9677971391558697"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"r0hIZHoGctiz","colab_type":"code","outputId":"8de6f2bb-91c7-410c-f854-c7353701cfd5","executionInfo":{"status":"ok","timestamp":1560252322187,"user_tz":-120,"elapsed":1567846,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":199}},"source":["X_train   = X\n","y_train   = y\n","tokenizer = text.Tokenizer(num_words=max_features, oov_token='unknown')\n","tokenizer.fit_on_texts(X_train)\n","\n","list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n","list_tokenized_test  = tokenizer.texts_to_sequences(X_test)\n","X_train = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n","X_test  = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen)\n","\n","model   = gru_keras(max_features, maxlen, dropout_rate, embed_dim, rec_units, reduction='average')\n","\n","y_train = np.array(y_train)\n","y_test  = np.array(y_test)\n","\n","print('Fitting')\n","model.fit(X_train, y_train,   batch_size=batch_size, epochs=epochs, shuffle=False, verbose=1)\n","probs = model.predict(X_test, batch_size=batch_size, verbose=1)\n","auc_f = average_precision_score(y_test, probs)\n","roc_f = roc_auc_score(y_test, probs)\n","model.save_weights(f'{models_path}/BGRU_avpool.h5')\n","del model"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Fitting\n","Epoch 1/4\n","158719/158719 [==============================] - 70s 439us/step - loss: 0.2180 - acc: 0.9288\n","Epoch 2/4\n","158719/158719 [==============================] - 68s 431us/step - loss: 0.1660 - acc: 0.9450\n","Epoch 3/4\n","158719/158719 [==============================] - 69s 432us/step - loss: 0.1146 - acc: 0.9582\n","Epoch 4/4\n","158719/158719 [==============================] - 69s 432us/step - loss: 0.1018 - acc: 0.9613\n","64830/64830 [==============================] - 10s 153us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gmjiSTh4PCSA","colab_type":"code","outputId":"e847e06c-d293-4486-c5b9-b9e12bc1ae5c","executionInfo":{"status":"ok","timestamp":1560252322191,"user_tz":-120,"elapsed":1565201,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["auc_f"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8543239389984293"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"k-ptNl8KDarn","colab_type":"code","outputId":"d7b9910a-3510-492c-9e9b-4a11a66a73fe","executionInfo":{"status":"ok","timestamp":1560252322192,"user_tz":-120,"elapsed":1559155,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["roc_f"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9713376946525165"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"SpUknIrXj0lM","colab_type":"text"},"source":["### Maximum Pooling"]},{"cell_type":"code","metadata":{"id":"Tir9BE9Ul5Ps","colab_type":"code","outputId":"5c5fbc8f-7ac4-49ef-e9a7-bfcffef9f1ee","executionInfo":{"status":"ok","timestamp":1560253625217,"user_tz":-120,"elapsed":2600959,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":1365}},"source":["c=0 # added later, this is why model shows folds starting with 5\n","# MAXIMUM POOLING\n","for train_index, val_index in kf.split(X, y):\n","    print(f' fold {c}')\n","    X_train, X_val       = X[train_index], X[val_index]\n","    y_train, y_val       = y[train_index], y[val_index] \n","    #tokenizer = text.Tokenizer(num_words=max_features)\n","    #tokenizer.fit_on_texts(pd.concat([X_train, unlab.comment_text], axis=0))\n","    list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n","    list_tokenized_val   = tokenizer.texts_to_sequences(X_val)\n","    X_train              = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n","    X_val                = sequence.pad_sequences(list_tokenized_val, maxlen=maxlen)\n","    model                = gru_keras(max_features, maxlen, dropout_rate, embed_dim, rec_units, reduction='maximum')\n","    print('Fitting')\n","    history              = model.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val), epochs=4, shuffle=False, verbose=1)\n","    probs                = model.predict(X_val, batch_size=batch_size, verbose=1)\n","    \n","    model.save_weights(f'{cv_models_path}/BGRU_maxpool_fold_{c}.h5')\n","    \n","    auc_f                = average_precision_score(y_val, probs)\n","    auc.append(auc_f)\n","    roc_f                = roc_auc_score(y_val, probs)\n","    roc.append(roc_f)\n","    print(f' average precision {auc_f}')\n","    print(f' roc auc {roc_f}')\n","    c += 1\n","    del model"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" fold 5\n","Fitting\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","Train on 126974 samples, validate on 31745 samples\n","Epoch 1/4\n","126974/126974 [==============================] - 63s 493us/step - loss: 0.1689 - acc: 0.9378 - val_loss: 0.1547 - val_acc: 0.9455\n","Epoch 2/4\n","126974/126974 [==============================] - 61s 480us/step - loss: 0.1086 - acc: 0.9578 - val_loss: 0.1495 - val_acc: 0.9476\n","Epoch 3/4\n","126974/126974 [==============================] - 61s 480us/step - loss: 0.1010 - acc: 0.9604 - val_loss: 0.1466 - val_acc: 0.9502\n","Epoch 4/4\n","126974/126974 [==============================] - 61s 481us/step - loss: 0.0964 - acc: 0.9628 - val_loss: 0.1452 - val_acc: 0.9515\n","31745/31745 [==============================] - 5s 160us/step\n"," average precision 0.8772565344100596\n"," roc auc 0.9720347282415762\n"," fold 6\n","Fitting\n","Train on 126974 samples, validate on 31745 samples\n","Epoch 1/4\n","126974/126974 [==============================] - 63s 494us/step - loss: 0.1720 - acc: 0.9386 - val_loss: 0.1506 - val_acc: 0.9471\n","Epoch 2/4\n","126974/126974 [==============================] - 61s 478us/step - loss: 0.1084 - acc: 0.9583 - val_loss: 0.1568 - val_acc: 0.9479\n","Epoch 3/4\n","126974/126974 [==============================] - 61s 481us/step - loss: 0.1015 - acc: 0.9602 - val_loss: 0.1458 - val_acc: 0.9499\n","Epoch 4/4\n","126974/126974 [==============================] - 61s 481us/step - loss: 0.0970 - acc: 0.9622 - val_loss: 0.1388 - val_acc: 0.9532\n","31745/31745 [==============================] - 5s 163us/step\n"," average precision 0.8760430546251339\n"," roc auc 0.9698458985396322\n"," fold 7\n","Fitting\n","Train on 126976 samples, validate on 31743 samples\n","Epoch 1/4\n","126976/126976 [==============================] - 63s 494us/step - loss: 0.1743 - acc: 0.9378 - val_loss: 0.1465 - val_acc: 0.9473\n","Epoch 2/4\n","126976/126976 [==============================] - 61s 478us/step - loss: 0.1096 - acc: 0.9575 - val_loss: 0.1488 - val_acc: 0.9479\n","Epoch 3/4\n","126976/126976 [==============================] - 61s 481us/step - loss: 0.1023 - acc: 0.9597 - val_loss: 0.1417 - val_acc: 0.9502\n","Epoch 4/4\n","126976/126976 [==============================] - 61s 482us/step - loss: 0.0981 - acc: 0.9616 - val_loss: 0.1395 - val_acc: 0.9506\n","31743/31743 [==============================] - 5s 164us/step\n"," average precision 0.8834236631091578\n"," roc auc 0.9729049986457566\n"," fold 8\n","Fitting\n","Train on 126976 samples, validate on 31743 samples\n","Epoch 1/4\n","126976/126976 [==============================] - 63s 497us/step - loss: 0.1694 - acc: 0.9397 - val_loss: 0.1496 - val_acc: 0.9421\n","Epoch 2/4\n","126976/126976 [==============================] - 61s 481us/step - loss: 0.1076 - acc: 0.9591 - val_loss: 0.1409 - val_acc: 0.9443\n","Epoch 3/4\n","126976/126976 [==============================] - 61s 481us/step - loss: 0.0993 - acc: 0.9617 - val_loss: 0.1403 - val_acc: 0.9463\n","Epoch 4/4\n","126976/126976 [==============================] - 61s 481us/step - loss: 0.0946 - acc: 0.9637 - val_loss: 0.1393 - val_acc: 0.9472\n","31743/31743 [==============================] - 5s 166us/step\n"," average precision 0.8294068581386531\n"," roc auc 0.9684921798070727\n"," fold 9\n","Fitting\n","Train on 126976 samples, validate on 31743 samples\n","Epoch 1/4\n","126976/126976 [==============================] - 63s 498us/step - loss: 0.1655 - acc: 0.9409 - val_loss: 0.3981 - val_acc: 0.9011\n","Epoch 2/4\n","126976/126976 [==============================] - 61s 477us/step - loss: 0.1024 - acc: 0.9620 - val_loss: 0.2884 - val_acc: 0.9139\n","Epoch 3/4\n","126976/126976 [==============================] - 61s 478us/step - loss: 0.0949 - acc: 0.9644 - val_loss: 0.2579 - val_acc: 0.9181\n","Epoch 4/4\n","126976/126976 [==============================] - 61s 481us/step - loss: 0.0902 - acc: 0.9662 - val_loss: 0.2238 - val_acc: 0.9242\n","31743/31743 [==============================] - 5s 167us/step\n"," average precision 0.7956255368693919\n"," roc auc 0.9668493733316924\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PJk3FwJ1jdEr","colab_type":"code","outputId":"e29d8ae2-ab0c-4547-d270-7ec2dcb72ca9","executionInfo":{"status":"ok","timestamp":1560253625219,"user_tz":-120,"elapsed":2600572,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["np.array(auc).mean()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8521627725963542"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"XDvEj-CAjd90","colab_type":"code","outputId":"c72946c2-f4fd-4dcb-bd08-a29bef129470","executionInfo":{"status":"ok","timestamp":1560253625220,"user_tz":-120,"elapsed":2600299,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["np.array(roc).mean()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9689112874345079"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"Yr41POAKjhIK","colab_type":"code","outputId":"421b664e-a03a-4f72-bd91-b6f1b2aad59d","executionInfo":{"status":"ok","timestamp":1560253937514,"user_tz":-120,"elapsed":2912299,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":199}},"source":["X_train = X\n","y_train = y\n","\n","tokenizer            = text.Tokenizer(num_words=max_features, oov_token='unknown')\n","tokenizer.fit_on_texts(X_train)\n","\n","list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n","#list_tokenized_test  = tokenizer.texts_to_sequences(X_test)\n","X_train = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n","X_test = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen)\n","\n","model = gru_keras(max_features, maxlen, dropout_rate, embed_dim, rec_units, reduction='maximum')\n","\n","y_train              = np.array(y_train)\n","y_test               = np.array(y_test)\n","\n","print('Fitting')\n","model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, shuffle=False, verbose=1)\n","probs = model.predict(X_test, batch_size=batch_size, verbose=1)\n","auc_f = average_precision_score(y_test, probs)\n","roc_f = roc_auc_score(y_test, probs)\n","model.save_weights(f'{models_path}/BGRU_maxpool.h5')\n","del model"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Fitting\n","Epoch 1/4\n","158719/158719 [==============================] - 73s 458us/step - loss: 0.1606 - acc: 0.9419\n","Epoch 2/4\n","158719/158719 [==============================] - 71s 446us/step - loss: 0.1049 - acc: 0.9596\n","Epoch 3/4\n","158719/158719 [==============================] - 71s 446us/step - loss: 0.0986 - acc: 0.9620\n","Epoch 4/4\n","158719/158719 [==============================] - 71s 447us/step - loss: 0.0946 - acc: 0.9635\n","64830/64830 [==============================] - 10s 157us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mONuOlIjji8l","colab_type":"code","outputId":"236773d2-b9e9-4704-df43-b2d698c57a56","executionInfo":{"status":"ok","timestamp":1560253937516,"user_tz":-120,"elapsed":2912089,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["auc_f"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.853890338923986"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"bhvFWULljkhr","colab_type":"code","outputId":"023206fb-57d7-4d3c-9c47-aed8579f4979","executionInfo":{"status":"ok","timestamp":1560253937518,"user_tz":-120,"elapsed":2911877,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["roc_f"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9714551605769767"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"rJ5af49qjmpW","colab_type":"text"},"source":["### ATTENTION"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jkDiySu6jwj9","outputId":"2fe366d2-d55a-468e-9cc3-24ddb963227f","executionInfo":{"status":"ok","timestamp":1560257898164,"user_tz":-120,"elapsed":1609768,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":1290}},"source":["c = 0\n","for train_index, val_index in kf.split(X, y):\n","    print(f' fold {c}')\n","    X_train, X_val       = X[train_index], X[val_index]\n","    y_train, y_val       = y[train_index], y[val_index] \n","    #tokenizer = text.Tokenizer(num_words=max_features)\n","    #tokenizer.fit_on_texts(pd.concat([X_train, unlab.comment_text], axis=0))\n","    list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n","    list_tokenized_val   = tokenizer.texts_to_sequences(X_val)\n","    X_train              = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n","    X_val                = sequence.pad_sequences(list_tokenized_val, maxlen=maxlen)\n","    model                = gru_keras(max_features, maxlen, dropout_rate, embed_dim, rec_units, reduction='attention')\n","    print('Fitting')\n","    history              = model.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val), epochs=4, shuffle=False, verbose=1)\n","    probs                = model.predict(X_val, batch_size=batch_size, verbose=1)\n","    \n","    model.save_weights(f'{cv_models_path}/BGRU_attention_fold_{c}.h5')\n","    \n","    auc_f                = average_precision_score(y_val, probs)\n","    auc.append(auc_f)\n","    roc_f                = roc_auc_score(y_val, probs)\n","    roc.append(roc_f)\n","    print(f' average precision {auc_f}')\n","    print(f' roc auc {roc_f}')\n","    c += 1\n","    del model"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" fold 0\n","Fitting\n","Train on 126974 samples, validate on 31745 samples\n","Epoch 1/4\n","126974/126974 [==============================] - 79s 625us/step - loss: 0.2265 - acc: 0.9216 - val_loss: 0.1544 - val_acc: 0.9446\n","Epoch 2/4\n","126974/126974 [==============================] - 75s 594us/step - loss: 0.1585 - acc: 0.9434 - val_loss: 0.1761 - val_acc: 0.9452\n","Epoch 3/4\n","126974/126974 [==============================] - 75s 592us/step - loss: 0.1132 - acc: 0.9574 - val_loss: 0.1560 - val_acc: 0.9476\n","Epoch 4/4\n","126974/126974 [==============================] - 75s 594us/step - loss: 0.1059 - acc: 0.9594 - val_loss: 0.1618 - val_acc: 0.9471\n","31745/31745 [==============================] - 8s 238us/step\n"," average precision 0.869315370688949\n"," roc auc 0.9673301881493371\n"," fold 1\n","Fitting\n","Train on 126974 samples, validate on 31745 samples\n","Epoch 1/4\n","126974/126974 [==============================] - 79s 625us/step - loss: 0.2154 - acc: 0.9248 - val_loss: 0.1573 - val_acc: 0.9432\n","Epoch 2/4\n","126974/126974 [==============================] - 75s 593us/step - loss: 0.1260 - acc: 0.9536 - val_loss: 0.1561 - val_acc: 0.9458\n","Epoch 3/4\n","126974/126974 [==============================] - 75s 590us/step - loss: 0.1112 - acc: 0.9578 - val_loss: 0.1594 - val_acc: 0.9465\n","Epoch 4/4\n","126974/126974 [==============================] - 75s 592us/step - loss: 0.1054 - acc: 0.9592 - val_loss: 0.1560 - val_acc: 0.9487\n","31745/31745 [==============================] - 8s 241us/step\n"," average precision 0.8694880359979226\n"," roc auc 0.9627416597518407\n"," fold 2\n","Fitting\n","Train on 126976 samples, validate on 31743 samples\n","Epoch 1/4\n","126976/126976 [==============================] - 80s 628us/step - loss: 0.2416 - acc: 0.9195 - val_loss: 0.1602 - val_acc: 0.9482\n","Epoch 2/4\n","126976/126976 [==============================] - 74s 582us/step - loss: 0.1329 - acc: 0.9509 - val_loss: 0.1641 - val_acc: 0.9435\n","Epoch 3/4\n","126976/126976 [==============================] - 74s 581us/step - loss: 0.1160 - acc: 0.9565 - val_loss: 0.1596 - val_acc: 0.9469\n","Epoch 4/4\n","126976/126976 [==============================] - 74s 584us/step - loss: 0.1123 - acc: 0.9569 - val_loss: 0.1430 - val_acc: 0.9494\n","31743/31743 [==============================] - 8s 245us/step\n"," average precision 0.8757880910634336\n"," roc auc 0.9692172077949526\n"," fold 3\n","Fitting\n","Train on 126976 samples, validate on 31743 samples\n","Epoch 1/4\n","126976/126976 [==============================] - 80s 630us/step - loss: 0.2424 - acc: 0.9210 - val_loss: 0.1662 - val_acc: 0.9371\n","Epoch 2/4\n","126976/126976 [==============================] - 74s 582us/step - loss: 0.1307 - acc: 0.9528 - val_loss: 0.1610 - val_acc: 0.9405\n","Epoch 3/4\n","126976/126976 [==============================] - 74s 584us/step - loss: 0.1069 - acc: 0.9594 - val_loss: 0.1494 - val_acc: 0.9443\n","Epoch 4/4\n","126976/126976 [==============================] - 74s 583us/step - loss: 0.1018 - acc: 0.9613 - val_loss: 0.1512 - val_acc: 0.9435\n","31743/31743 [==============================] - 8s 248us/step\n"," average precision 0.8200801926273121\n"," roc auc 0.9649479102108635\n"," fold 4\n","Fitting\n","Train on 126976 samples, validate on 31743 samples\n","Epoch 1/4\n","126976/126976 [==============================] - 80s 632us/step - loss: 0.2309 - acc: 0.9241 - val_loss: 0.3693 - val_acc: 0.9002\n","Epoch 2/4\n","126976/126976 [==============================] - 73s 575us/step - loss: 0.2048 - acc: 0.9358 - val_loss: 0.3477 - val_acc: 0.9003\n","Epoch 3/4\n","126976/126976 [==============================] - 73s 574us/step - loss: 0.1183 - acc: 0.9584 - val_loss: 0.3152 - val_acc: 0.9133\n","Epoch 4/4\n","126976/126976 [==============================] - 73s 575us/step - loss: 0.1018 - acc: 0.9635 - val_loss: 0.3184 - val_acc: 0.9169\n","31743/31743 [==============================] - 8s 253us/step\n"," average precision 0.7784874503949201\n"," roc auc 0.9604282450268198\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"I6CuyhSAjwkB","outputId":"bf584176-fed2-41b5-c4ed-05e3b73db94d","executionInfo":{"status":"ok","timestamp":1560257898166,"user_tz":-120,"elapsed":1609093,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["np.array(auc).mean()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8525556411291078"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xvOwVZTBjwkC","outputId":"e0e341c6-0c6c-4f37-eb66-13da9f811e68","executionInfo":{"status":"ok","timestamp":1560257898167,"user_tz":-120,"elapsed":1608615,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["np.array(roc).mean()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9667035973653868"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9D1-IzxJjwkE","outputId":"94eae448-d1df-42e0-8d84-229913f285f7","executionInfo":{"status":"ok","timestamp":1560258279094,"user_tz":-120,"elapsed":1988948,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":199}},"source":["X_train = X\n","y_train = y\n","\n","tokenizer            = text.Tokenizer(num_words=max_features, oov_token='unknown')\n","tokenizer.fit_on_texts(X_train)\n","\n","list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n","#list_tokenized_test  = tokenizer.texts_to_sequences(X_test)\n","X_train = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n","X_test = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen)\n","\n","model = gru_keras(max_features, maxlen, dropout_rate, embed_dim, rec_units, reduction='attention')\n","\n","y_train              = np.array(y_train)\n","y_test               = np.array(y_test)\n","\n","print('Fitting')\n","model.fit(X_train, y_train, batch_size=batch_size, epochs=4, shuffle=False, verbose=1)\n","probs = model.predict(X_test, batch_size=batch_size, verbose=1)\n","\n","model.save_weights(f'{models_path}/BGRU_attention.h5')\n","\n","auc_f = average_precision_score(y_test, probs)\n","roc_f = roc_auc_score(y_test, probs)\n","del model"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Fitting\n","Epoch 1/4\n","158719/158719 [==============================] - 90s 567us/step - loss: 0.2186 - acc: 0.9226\n","Epoch 2/4\n","158719/158719 [==============================] - 85s 537us/step - loss: 0.1171 - acc: 0.9563\n","Epoch 3/4\n","158719/158719 [==============================] - 85s 538us/step - loss: 0.1066 - acc: 0.9597\n","Epoch 4/4\n","158719/158719 [==============================] - 86s 542us/step - loss: 0.1014 - acc: 0.9611\n","64830/64830 [==============================] - 15s 227us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"voxjlSrEjwkF","outputId":"c60f7c2f-95a1-4e46-e321-284746b2dc79","executionInfo":{"status":"ok","timestamp":1560258279098,"user_tz":-120,"elapsed":1987525,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["auc_f"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8489225428060403"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"A9LzdPIAjwkG","outputId":"c263bbf3-972a-4a06-c448-e369958bde06","executionInfo":{"status":"ok","timestamp":1560258279099,"user_tz":-120,"elapsed":1986853,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["roc_f"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9676813223421821"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"cFKdvFaWmqQU","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}