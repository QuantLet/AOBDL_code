{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"code_8_GRU_attention.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"SQoEzO-1eML0","colab_type":"code","outputId":"7c0f8415-e01f-4828-f709-5860b0658ec9","executionInfo":{"status":"ok","timestamp":1563277564716,"user_tz":-120,"elapsed":2635,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split, KFold\n","import random\n","\n","from sklearn.model_selection import cross_validate\n","from sklearn.metrics import roc_auc_score, average_precision_score\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","from keras.preprocessing import text, sequence\n","from keras.layers import Embedding, SpatialDropout1D\n","from keras.models import Model, Sequential\n","from keras.layers import Dense, Embedding, Input\n","from keras.optimizers import RMSprop\n","import keras.backend as K\n","from keras.layers import Dense, Input, GRU, LSTM, Bidirectional, Dropout, CuDNNLSTM, CuDNNGRU, GlobalAveragePooling1D, GlobalMaxPool1D\n","from sklearn.metrics import average_precision_score, roc_auc_score\n","from sklearn.model_selection import StratifiedKFold\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras.engine.topology import Layer, InputSpec\n","from keras import initializers as initializers, regularizers, constraints\n","\n","from numpy.random import seed\n","from tensorflow import set_random_seed\n","import random as rn\n","import os"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qCeSyw_eCrx4","colab_type":"code","outputId":"4ddab0ce-f49f-45bd-aa3f-6e4baa6645f7","executionInfo":{"status":"ok","timestamp":1563277564720,"user_tz":-120,"elapsed":2629,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# GOOGLE COLAB SETUP\n","\n","# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nak1uhxiEK0R","colab_type":"code","colab":{}},"source":["#2. Get the file\n","data_path          = 'drive/My Drive/Colab Notebooks/adaptHAN/AOBDL_code/data'\n","codes_path         = 'drive/My Drive/Colab Notebooks/adaptHAN/AOBDL_code/codes'\n","cv_models_path     = 'drive/My Drive/Colab Notebooks/adaptHAN/AOBDL_code/cv_models'\n","models_path        = 'drive/My Drive/Colab Notebooks/adaptHAN/AOBDL_code/models'\n","\n","\n","#3. Read file as panda dataframe\n","train         = pd.read_csv(f'{data_path}/train_cleaned_no_punkt.csv') \n","test_labelled = pd.read_csv(f'{data_path}/test_labelled_cleaned_no_punkt.csv') \n","test_unlabelled = pd.read_csv(f'{data_path}/test_unlabelled_cleaned_no_punkt.csv') "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f3ZeAcM_eGpj","colab_type":"code","colab":{}},"source":["train['mal']         = train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) >= 1  \n","train.drop(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'], axis=1, inplace=True)\n","train.comment_text.fillna(\"empty\", inplace=True)\n","\n","test_labelled['mal'] = test_labelled[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) >= 1  \n","test_labelled.drop(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'], axis=1, inplace=True)\n","test_labelled.comment_text.fillna(\"empty\", inplace=True)\n","\n","test_unlabelled.comment_text.fillna(\"empty\", inplace=True)\n","\n","# CHANGE TRAIN AND TEST, MIX TO GET SIMILAR DISTRIBUTION\n","from sklearn.model_selection import train_test_split\n","rs=42\n","X_train1, X_test1, y_train1, y_test1  = train_test_split(train.drop('mal', axis=1), train.mal, stratify=train.mal, test_size=0.29, random_state=rs )\n","X_train2, X_test2, y_train2, y_test2  = train_test_split(test_labelled.drop('mal', axis=1), test_labelled.mal, stratify=test_labelled.mal, test_size=0.29, random_state=rs)\n","\n","X = np.concatenate((X_train1.comment_text, X_train2.comment_text))\n","y = np.concatenate((y_train1, y_train2))\n","\n","X_test = np.concatenate((X_test1.comment_text, X_test2.comment_text))\n","y_test = np.concatenate((y_test1, y_test2))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pWPSaXneFFZu","colab_type":"code","colab":{}},"source":["#X = train.comment_text\n","#y = train.mal\n","\n","max_features = 40000\n","maxlen       = 400\n","dropout_rate = 0.25\n","rs           = 42\n","epochs       = 4\n","batch_size   = 256\n","embed_dim    = 50\n","rec_units    = 150\n","\n","\n","\n","\n","seed(rs)\n","set_random_seed(rs)\n","rn.seed(rs)\n","\n","os.environ['PYTHONHASHSEED']=str(rs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4DPm1-btWNGB","colab_type":"code","colab":{}},"source":["def dot_product(x, kernel):\n","    if K.backend() == 'tensorflow':\n","        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n","    else:\n","        return K.dot(x, kernel)\n","\n","class AttentionWithContext(Layer):\n","    def __init__(self,\n","                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n","                 W_constraint=None, u_constraint=None, b_constraint=None,\n","                 bias=True, **kwargs):\n","\n","        self.supports_masking = True\n","        self.init = initializers.get('glorot_uniform')\n","\n","        self.W_regularizer = regularizers.get(W_regularizer)\n","        self.u_regularizer = regularizers.get(u_regularizer)\n","        self.b_regularizer = regularizers.get(b_regularizer)\n","\n","        self.W_constraint = constraints.get(W_constraint)\n","        self.u_constraint = constraints.get(u_constraint)\n","        self.b_constraint = constraints.get(b_constraint)\n","\n","        self.bias = bias\n","        super(AttentionWithContext, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 3\n","\n","        self.W = self.add_weight((input_shape[-1], input_shape[-1]),\n","                                 initializer=self.init,\n","                                 name='{}_W'.format(self.name),\n","                                 regularizer=self.W_regularizer,\n","                                 constraint=self.W_constraint)\n","        if self.bias:\n","            self.b = self.add_weight((input_shape[-1],),\n","                                     initializer='zero',\n","                                     name='{}_b'.format(self.name),\n","                                     regularizer=self.b_regularizer,\n","                                     constraint=self.b_constraint)\n","\n","        self.u = self.add_weight((input_shape[-1],),\n","                                 initializer=self.init,\n","                                 name='{}_u'.format(self.name),\n","                                 regularizer=self.u_regularizer,\n","                                 constraint=self.u_constraint)\n","\n","        super(AttentionWithContext, self).build(input_shape)\n","\n","    def compute_mask(self, input, input_mask=None):\n","        return None\n","\n","    def call(self, x, mask=None):\n","        uit = dot_product(x, self.W)\n","\n","        if self.bias:\n","            uit += self.b\n","\n","        uit = K.tanh(uit)\n","        ait = dot_product(uit, self.u)\n","\n","        a = K.exp(ait)\n","\n","        if mask is not None:\n","            # Cast the mask to floatX to avoid float64 upcasting in theano\n","            a *= K.cast(mask, K.floatx())\n","\n","        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n","\n","        a = K.expand_dims(a)\n","        weighted_input = x * a\n","        return K.sum(weighted_input, axis=1)\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape[0], input_shape[-1]\n","      \n","      \n","      \n","class AttLayer(Layer):\n","    def __init__(self, attention_dim):\n","        self.init = initializers.get('normal')\n","        self.supports_masking = True\n","        self.attention_dim = attention_dim\n","        super(AttLayer, self).__init__()\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 3\n","        self.W = K.variable(self.init((input_shape[-1], self.attention_dim)))\n","        self.b = K.variable(self.init((self.attention_dim, )))\n","        self.u = K.variable(self.init((self.attention_dim, 1)))\n","        self.trainable_weights = [self.W, self.b, self.u]\n","        super(AttLayer, self).build(input_shape)\n","\n","    def compute_mask(self, inputs, mask=None):\n","        return mask\n","\n","    def call(self, x, mask=None):\n","        # size of x :[batch_size, sel_len, attention_dim]\n","        # size of u :[batch_size, attention_dim]\n","        # uit = tanh(xW+b)\n","        uit = K.tanh(K.bias_add(K.dot(x, self.W), self.b))\n","        ait = K.dot(uit, self.u)\n","        ait = K.squeeze(ait, -1)\n","\n","        ait = K.exp(ait)\n","\n","        if mask is not None:\n","            # Cast the mask to floatX to avoid float64 upcasting in theano\n","            ait *= K.cast(mask, K.floatx())\n","        ait /= K.cast(K.sum(ait, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n","        ait = K.expand_dims(ait)\n","        weighted_input = x * ait\n","        output = K.sum(weighted_input, axis=1)\n","\n","        return output\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0], input_shape[-1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ac0ThFO3FIHI","colab_type":"code","colab":{}},"source":["def gru_keras(max_features, maxlen, dropout_rate, embed_dim, rec_units, reduction = 'average'):\n","    if K.backend == 'tensorflow':        \n","        K.clear_session()\n","    input_layer = Input(shape=(maxlen,))\n","    embedding_layer = Embedding(max_features, output_dim=embed_dim, trainable=True)(input_layer)\n","    x = SpatialDropout1D(dropout_rate)(embedding_layer)\n","    x = CuDNNGRU(units=rec_units, return_sequences=True)(x)\n","    if reduction == 'average':\n","      x = GlobalAveragePooling1D()(x)\n","    elif reduction == 'maximum':\n","      x = GlobalMaxPool1D()(x)\n","    elif reduction == 'attention':\n","      x = AttentionWithContext()(x)\n","      \n","    output_layer = Dense(1, activation=\"sigmoid\")(x)\n","    model = Model(inputs=input_layer, outputs=output_layer)\n","    model.compile(loss='binary_crossentropy',\n","                  optimizer=RMSprop(clipvalue=1, clipnorm=1),\n","                  metrics=['acc'])\n","    #print( model.summary())\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BFgVXjNPF-dM","colab_type":"code","colab":{}},"source":["kf = StratifiedKFold(n_splits=5, random_state=rs)\n","auc = []\n","roc = []\n","c = 0\n","#tokenizer = text.Tokenizer(num_words=max_features)\n","#tokenizer.fit_on_texts(X)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jjvUHMVYj3qv","colab_type":"text"},"source":["### Average Pooling"]},{"cell_type":"code","metadata":{"id":"-49hvW4_GHww","colab_type":"code","outputId":"62828088-b434-49b0-edf2-98627a6ce9da","executionInfo":{"status":"ok","timestamp":1563279160873,"user_tz":-120,"elapsed":1598743,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["c=0\n","for train_index, val_index in kf.split(X, y):\n","    print(f' fold {c}')\n","    X_train, X_val       = X[train_index], X[val_index]\n","    y_train, y_val       = y[train_index], y[val_index] \n","    tokenizer = text.Tokenizer(num_words=max_features)\n","    tokenizer.fit_on_texts(X_train)\n","    list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n","    list_tokenized_val   = tokenizer.texts_to_sequences(X_val)\n","    X_train              = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n","    X_val                = sequence.pad_sequences(list_tokenized_val, maxlen=maxlen)\n","    model                = gru_keras(max_features, maxlen, dropout_rate, embed_dim, rec_units)\n","    print('Fitting')\n","    history              = model.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val), epochs=4, shuffle=True, verbose=1)\n","    probs                = model.predict(X_val, batch_size=batch_size, verbose=1)\n","    \n","    model.save_weights(f'{cv_models_path}/GRU_avpool_fold_{c}.h5')\n","    \n","    auc_f                = average_precision_score(y_val, probs)\n","    auc.append(auc_f)\n","    roc_f                = roc_auc_score(y_val, probs)\n","    roc.append(roc_f)\n","    print(f' average precision {round(auc_f,3)}')\n","    print(f' roc auc {round(roc_f,3)}')\n","    c += 1\n","    del model"],"execution_count":9,"outputs":[{"output_type":"stream","text":[" fold 0\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0716 11:46:23.010349 140227565778816 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0716 11:46:23.012618 140227565778816 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0716 11:46:23.016841 140227565778816 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0716 11:46:23.050101 140227565778816 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","W0716 11:46:23.061267 140227565778816 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","W0716 11:46:23.790701 140227565778816 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0716 11:46:23.799431 140227565778816 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","W0716 11:46:23.810670 140227565778816 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Fitting\n","Train on 126974 samples, validate on 31745 samples\n","Epoch 1/4\n","126974/126974 [==============================] - 76s 597us/step - loss: 0.3865 - acc: 0.8887 - val_loss: 0.2538 - val_acc: 0.9053\n","Epoch 2/4\n","126974/126974 [==============================] - 74s 581us/step - loss: 0.2343 - acc: 0.9093 - val_loss: 0.2134 - val_acc: 0.9191\n","Epoch 3/4\n","126974/126974 [==============================] - 74s 580us/step - loss: 0.2019 - acc: 0.9223 - val_loss: 0.2026 - val_acc: 0.9248\n","Epoch 4/4\n","126974/126974 [==============================] - 74s 581us/step - loss: 0.1878 - acc: 0.9273 - val_loss: 0.1745 - val_acc: 0.9335\n","31745/31745 [==============================] - 5s 162us/step\n"," average precision 0.792\n"," roc auc 0.936\n"," fold 1\n","Fitting\n","Train on 126974 samples, validate on 31745 samples\n","Epoch 1/4\n","126974/126974 [==============================] - 74s 586us/step - loss: 0.2946 - acc: 0.9005 - val_loss: 0.2451 - val_acc: 0.9067\n","Epoch 2/4\n","126974/126974 [==============================] - 73s 576us/step - loss: 0.2360 - acc: 0.9076 - val_loss: 0.2185 - val_acc: 0.9215\n","Epoch 3/4\n","126974/126974 [==============================] - 73s 577us/step - loss: 0.2061 - acc: 0.9190 - val_loss: 0.1848 - val_acc: 0.9250\n","Epoch 4/4\n","126974/126974 [==============================] - 74s 581us/step - loss: 0.1949 - acc: 0.9245 - val_loss: 0.1811 - val_acc: 0.9303\n","31745/31745 [==============================] - 5s 164us/step\n"," average precision 0.782\n"," roc auc 0.931\n"," fold 2\n","Fitting\n","Train on 126976 samples, validate on 31743 samples\n","Epoch 1/4\n","126976/126976 [==============================] - 75s 587us/step - loss: 0.4743 - acc: 0.8560 - val_loss: 0.2623 - val_acc: 0.9027\n","Epoch 2/4\n","126976/126976 [==============================] - 74s 584us/step - loss: 0.2762 - acc: 0.8938 - val_loss: 0.2196 - val_acc: 0.9158\n","Epoch 3/4\n","126976/126976 [==============================] - 74s 583us/step - loss: 0.2275 - acc: 0.9121 - val_loss: 0.1859 - val_acc: 0.9290\n","Epoch 4/4\n","126976/126976 [==============================] - 73s 578us/step - loss: 0.1990 - acc: 0.9228 - val_loss: 0.1767 - val_acc: 0.9328\n","31743/31743 [==============================] - 5s 163us/step\n"," average precision 0.777\n"," roc auc 0.932\n"," fold 3\n","Fitting\n","Train on 126976 samples, validate on 31743 samples\n","Epoch 1/4\n","126976/126976 [==============================] - 74s 585us/step - loss: 0.2969 - acc: 0.8981 - val_loss: 0.2565 - val_acc: 0.9026\n","Epoch 2/4\n","126976/126976 [==============================] - 74s 579us/step - loss: 0.2334 - acc: 0.9093 - val_loss: 0.2226 - val_acc: 0.9128\n","Epoch 3/4\n","126976/126976 [==============================] - 74s 580us/step - loss: 0.2930 - acc: 0.9084 - val_loss: 0.2019 - val_acc: 0.9234\n","Epoch 4/4\n","126976/126976 [==============================] - 74s 582us/step - loss: 0.1820 - acc: 0.9288 - val_loss: 0.1876 - val_acc: 0.9292\n","31743/31743 [==============================] - 5s 164us/step\n"," average precision 0.687\n"," roc auc 0.932\n"," fold 4\n","Fitting\n","Train on 126976 samples, validate on 31743 samples\n","Epoch 1/4\n","126976/126976 [==============================] - 75s 587us/step - loss: 0.2962 - acc: 0.8983 - val_loss: 0.2628 - val_acc: 0.9006\n","Epoch 2/4\n","126976/126976 [==============================] - 74s 580us/step - loss: 0.2277 - acc: 0.9133 - val_loss: 0.2409 - val_acc: 0.9043\n","Epoch 3/4\n","126976/126976 [==============================] - 74s 580us/step - loss: 0.1870 - acc: 0.9282 - val_loss: 0.2129 - val_acc: 0.9140\n","Epoch 4/4\n","126976/126976 [==============================] - 74s 582us/step - loss: 0.1843 - acc: 0.9283 - val_loss: 0.2119 - val_acc: 0.9152\n","31743/31743 [==============================] - 5s 167us/step\n"," average precision 0.587\n"," roc auc 0.926\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oD-G2cO9GLz3","colab_type":"code","colab":{}},"source":["data = pd.DataFrame({'acc':history.history['acc'],\n","                    'loss': history.history['loss'],\n","                    'val_acc': history.history['val_acc'],\n","                    'val_loss': history.history['val_loss']})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S51--4EBjMKx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"3b4f8f57-cb82-459e-dbfc-f530600aa3ee","executionInfo":{"status":"ok","timestamp":1563279160879,"user_tz":-120,"elapsed":1598732,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}}},"source":["round(np.array(auc).mean(), 3)"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.725"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"EPtxc1qPTfoC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"c788b84d-7e8f-48f5-b78f-4e400a149bd2","executionInfo":{"status":"ok","timestamp":1563279160880,"user_tz":-120,"elapsed":1598725,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}}},"source":["round(np.array(roc).mean(),3)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.932"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"r0hIZHoGctiz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"d73ac131-a366-47ff-c3a7-cfce169a7427","executionInfo":{"status":"ok","timestamp":1563279544889,"user_tz":-120,"elapsed":360338,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}}},"source":["X_train   = X\n","y_train   = y\n","tokenizer = text.Tokenizer(num_words=max_features, oov_token='unknown')\n","tokenizer.fit_on_texts(X_train)\n","\n","list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n","list_tokenized_test  = tokenizer.texts_to_sequences(X_test)\n","X_train = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n","X_test  = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen)\n","\n","model   = gru_keras(max_features, maxlen, dropout_rate, embed_dim, rec_units, reduction='average')\n","\n","y_train = np.array(y_train)\n","y_test  = np.array(y_test)\n","\n","print('Fitting')\n","model.fit(X_train, y_train,   batch_size=batch_size, epochs=epochs, shuffle=True, verbose=1)\n","probs = model.predict(X_test, batch_size=batch_size, verbose=1)\n","auc_f = average_precision_score(y_test, probs)\n","roc_f = roc_auc_score(y_test, probs)\n","model.save_weights(f'{models_path}/GRU_avpool.h5')\n","del model"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Fitting\n","Epoch 1/4\n","158719/158719 [==============================] - 88s 556us/step - loss: 0.3041 - acc: 0.8940\n","Epoch 2/4\n","158719/158719 [==============================] - 87s 549us/step - loss: 0.2339 - acc: 0.9083\n","Epoch 3/4\n","158719/158719 [==============================] - 87s 551us/step - loss: 0.2169 - acc: 0.9192\n","Epoch 4/4\n","158719/158719 [==============================] - 87s 549us/step - loss: 0.1923 - acc: 0.9276\n","64830/64830 [==============================] - 11s 167us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gmjiSTh4PCSA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e567331a-6d84-4e5d-976b-918121a11738","executionInfo":{"status":"ok","timestamp":1563279545120,"user_tz":-120,"elapsed":146,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}}},"source":["round(auc_f,3)"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.696"]},"metadata":{"tags":[]},"execution_count":14},{"output_type":"execute_result","data":{"text/plain":["0.696"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"k-ptNl8KDarn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ca1c572a-1aa4-4ed0-84d5-3d5e27dd5197","executionInfo":{"status":"ok","timestamp":1563279545121,"user_tz":-120,"elapsed":19,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}}},"source":["round(roc_f,3)"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.936"]},"metadata":{"tags":[]},"execution_count":15},{"output_type":"execute_result","data":{"text/plain":["0.936"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"SpUknIrXj0lM","colab_type":"text"},"source":["### Maximum Pooling"]},{"cell_type":"code","metadata":{"id":"Tir9BE9Ul5Ps","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"643377ed-eb14-485c-d8a8-56e358bf0425","executionInfo":{"status":"error","timestamp":1563279968100,"user_tz":-120,"elapsed":422981,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}}},"source":["c=0 # added later, this is why model shows folds starting with 5\n","# MAXIMUM POOLING\n","for train_index, val_index in kf.split(X, y):\n","    print(f' fold {c}')\n","    X_train, X_val       = X[train_index], X[val_index]\n","    y_train, y_val       = y[train_index], y[val_index] \n","    tokenizer = text.Tokenizer(num_words=max_features)\n","    tokenizer.fit_on_texts(X_train)\n","    list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n","    list_tokenized_val   = tokenizer.texts_to_sequences(X_val)\n","    X_train              = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n","    X_val                = sequence.pad_sequences(list_tokenized_val, maxlen=maxlen)\n","    model                = gru_keras(max_features, maxlen, dropout_rate, embed_dim, rec_units, reduction='maximum')\n","    print('Fitting')\n","    history              = model.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val), epochs=4, shuffle=True, verbose=1)\n","    probs                = model.predict(X_val, batch_size=batch_size, verbose=1)\n","    \n","    model.save_weights(f'{cv_models_path}/GRU_maxpool_fold_{c}.h5')\n","    \n","    auc_f                = average_precision_score(y_val, probs)\n","    auc.append(auc_f)\n","    roc_f                = roc_auc_score(y_val, probs)\n","    roc.append(roc_f)\n","    print(f' average precision {round(auc_f,3)}')\n","    print(f' roc auc {round(roc_f,3)}')\n","    c += 1\n","    del model"],"execution_count":16,"outputs":[{"output_type":"stream","text":[" fold 0\n"," fold 0\n","Fitting\n","Fitting\n","Train on 126974 samples, validate on 31745 samples\n","Epoch 1/4\n","Train on 126974 samples, validate on 31745 samples\n","Epoch 1/4\n","126974/126974 [==============================] - 77s 608us/step - loss: 0.1935 - acc: 0.9306 - val_loss: 0.1197 - val_acc: 0.9558\n","126974/126974 [==============================] - 77s 608us/step - loss: 0.1935 - acc: 0.9306 - val_loss: 0.1197 - val_acc: 0.9558\n","Epoch 2/4\n","   256/126974 [..............................] - ETA: 1:16 - loss: 0.1506 - acc: 0.9297Epoch 2/4\n","126974/126974 [==============================] - 76s 599us/step - loss: 0.1227 - acc: 0.9520 - val_loss: 0.1155 - val_acc: 0.9573\n","126974/126974 [==============================] - 76s 599us/step - loss: 0.1227 - acc: 0.9520 - val_loss: 0.1155 - val_acc: 0.9573\n","Epoch 3/4\n","   256/126974 [..............................] - ETA: 1:13 - loss: 0.1080 - acc: 0.9609Epoch 3/4\n","126974/126974 [==============================] - 76s 601us/step - loss: 0.1139 - acc: 0.9554 - val_loss: 0.1117 - val_acc: 0.9603\n","126974/126974 [==============================] - 76s 601us/step - loss: 0.1139 - acc: 0.9554 - val_loss: 0.1117 - val_acc: 0.9603\n","Epoch 4/4\n","   256/126974 [..............................] - ETA: 1:11 - loss: 0.0904 - acc: 0.9609Epoch 4/4\n","126974/126974 [==============================] - 76s 601us/step - loss: 0.1085 - acc: 0.9572 - val_loss: 0.1109 - val_acc: 0.9604\n","126974/126974 [==============================] - 76s 601us/step - loss: 0.1085 - acc: 0.9572 - val_loss: 0.1109 - val_acc: 0.9604\n","31745/31745 [==============================] - 6s 174us/step\n","31745/31745 [==============================] - 6s 174us/step\n"," average precision 0.886\n"," roc auc 0.974\n"," fold 1\n"," average precision 0.886\n"," roc auc 0.974\n"," fold 1\n","Fitting\n","Fitting\n","Train on 126974 samples, validate on 31745 samples\n","Epoch 1/4\n","Train on 126974 samples, validate on 31745 samples\n","Epoch 1/4\n","126720/126974 [============================>.] - ETA: 0s - loss: 0.1926 - acc: 0.9320"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-f2b60742223e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m                \u001b[0;34m=\u001b[0m \u001b[0mgru_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fitting'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mhistory\u001b[0m              \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mprobs\u001b[0m                \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[1;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                                              verbose=0)\n\u001b[0m\u001b[1;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-f2b60742223e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m                \u001b[0;34m=\u001b[0m \u001b[0mgru_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fitting'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mhistory\u001b[0m              \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mprobs\u001b[0m                \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[1;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                                              verbose=0)\n\u001b[0m\u001b[1;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"PJk3FwJ1jdEr","colab_type":"code","colab":{}},"source":["round(np.array(auc).mean(),3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XDvEj-CAjd90","colab_type":"code","colab":{}},"source":["round(np.array(roc).mean(),3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yr41POAKjhIK","colab_type":"code","colab":{}},"source":["X_train = X\n","y_train = y\n","\n","tokenizer            = text.Tokenizer(num_words=max_features, oov_token='unknown')\n","tokenizer.fit_on_texts(X_train)\n","\n","list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n","#list_tokenized_test  = tokenizer.texts_to_sequences(X_test)\n","X_train = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n","X_test = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen)\n","\n","model = gru_keras(max_features, maxlen, dropout_rate, embed_dim, rec_units, reduction='maximum')\n","\n","y_train              = np.array(y_train)\n","y_test               = np.array(y_test)\n","\n","print('Fitting')\n","model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, shuffle=True, verbose=1)\n","probs = model.predict(X_test, batch_size=batch_size, verbose=1)\n","auc_f = average_precision_score(y_test, probs)\n","roc_f = roc_auc_score(y_test, probs)\n","model.save_weights(f'{models_path}/GRU_maxpool.h5')\n","del model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mONuOlIjji8l","colab_type":"code","colab":{}},"source":["round(auc_f,3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bhvFWULljkhr","colab_type":"code","colab":{}},"source":["round(roc_f,3)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rJ5af49qjmpW","colab_type":"text"},"source":["### ATTENTION"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jkDiySu6jwj9","colab":{}},"source":["c = 0\n","for train_index, val_index in kf.split(X, y):\n","    print(f' fold {c}')\n","    X_train, X_val       = X[train_index], X[val_index]\n","    y_train, y_val       = y[train_index], y[val_index] \n","    tokenizer = text.Tokenizer(num_words=max_features)\n","    tokenizer.fit_on_texts(X_train)\n","    list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n","    list_tokenized_val   = tokenizer.texts_to_sequences(X_val)\n","    X_train              = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n","    X_val                = sequence.pad_sequences(list_tokenized_val, maxlen=maxlen)\n","    model                = gru_keras(max_features, maxlen, dropout_rate, embed_dim, rec_units, reduction='attention')\n","    print('Fitting')\n","    history              = model.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val), epochs=4, shuffle=True, verbose=1)\n","    probs                = model.predict(X_val, batch_size=batch_size, verbose=1)\n","    \n","    model.save_weights(f'{cv_models_path}/GRU_attention_fold_{c}.h5')\n","    \n","    auc_f                = average_precision_score(y_val, probs)\n","    auc.append(auc_f)\n","    roc_f                = roc_auc_score(y_val, probs)\n","    roc.append(roc_f)\n","    print(f' average precision {round(auc_f,3)}')\n","    print(f' roc auc {round(roc_f,3)}')\n","    c += 1\n","    del model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"I6CuyhSAjwkB","colab":{}},"source":["round(np.array(auc).mean(),3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xvOwVZTBjwkC","colab":{}},"source":["round(np.array(roc).mean(),3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9D1-IzxJjwkE","colab":{}},"source":["X_train = X\n","y_train = y\n","\n","tokenizer            = text.Tokenizer(num_words=max_features, oov_token='unknown')\n","tokenizer.fit_on_texts(X_train)\n","\n","list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n","#list_tokenized_test  = tokenizer.texts_to_sequences(X_test)\n","X_train = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n","X_test = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen)\n","\n","model = gru_keras(max_features, maxlen, dropout_rate, embed_dim, rec_units, reduction='attention')\n","\n","y_train              = np.array(y_train)\n","y_test               = np.array(y_test)\n","\n","print('Fitting')\n","model.fit(X_train, y_train, batch_size=batch_size, epochs=4, shuffle=True, verbose=1)\n","probs = model.predict(X_test, batch_size=batch_size, verbose=1)\n","\n","model.save_weights(f'{models_path}/GRU_attention.h5')\n","\n","auc_f = average_precision_score(y_test, probs)\n","roc_f = roc_auc_score(y_test, probs)\n","del model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"voxjlSrEjwkF","colab":{}},"source":["round(auc_f,3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"A9LzdPIAjwkG","colab":{}},"source":["round(roc_f,3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cFKdvFaWmqQU","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}