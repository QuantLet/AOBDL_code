{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59gnBk5Hw5TS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble  import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import random\n",
    "\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import argparse\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 543,
     "status": "ok",
     "timestamp": 1559807604198,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg",
      "userId": "01253993997636551956"
     },
     "user_tz": -120
    },
    "id": "BqKp-tsqxyzv",
    "outputId": "d30b1414-0884-4c16-ae26-1f9b537b8baa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# GOOGLE COLAB SETUP\n",
    "\n",
    "# Load the Drive helper and mount\n",
    "from google.colab import drive\n",
    "\n",
    "# This will prompt for authorization.\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sRpOrXSow9Hv"
   },
   "outputs": [],
   "source": [
    "#2. Get the file\n",
    "data_path     = 'drive/My Drive/Colab Notebooks/adaptHAN/AOBDL_code/data'\n",
    "codes_path    = 'drive/My Drive/Colab Notebooks/adaptHAN/AOBDL_code/codes'\n",
    "\n",
    "\n",
    "#3. Read file as panda dataframe\n",
    "train         = pd.read_csv(f'{data_path}/train_cleaned_no_punkt.csv') \n",
    "test_labelled = pd.read_csv(f'{data_path}/test_labelled_cleaned_no_punkt.csv') \n",
    "test_unlabelled = pd.read_csv(f'{data_path}/test_unlabelled_cleaned_no_punkt.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Get the file\n",
    "data_path     = '../data'\n",
    "codes_path    = '../codes'\n",
    "\n",
    "\n",
    "#3. Read file as panda dataframe\n",
    "train         = pd.read_csv(f'{data_path}/train_cleaned_no_punkt.csv') \n",
    "test_labelled = pd.read_csv(f'{data_path}/test_labelled_cleaned_no_punkt.csv') \n",
    "test_unlabelled = pd.read_csv(f'{data_path}/test_unlabelled_cleaned_no_punkt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r1gJD_p_x25z"
   },
   "outputs": [],
   "source": [
    "train['mal'] = train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) >= 1  \n",
    "train.drop(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'], axis=1, inplace=True)\n",
    "train.comment_text.fillna(\"empty\", inplace=True)\n",
    "train = train.drop_duplicates(subset=['comment_text', 'mal'])\n",
    "\n",
    "test_labelled['mal'] = test_labelled[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) >= 1  \n",
    "test_labelled.drop(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'], axis=1, inplace=True)\n",
    "test_labelled.comment_text.fillna(\"empty\", inplace=True)\n",
    "test_labelled = test_labelled.drop_duplicates(subset=['comment_text'])\n",
    "\n",
    "test_unlabelled.comment_text.fillna(\"empty\", inplace=True)\n",
    "test_unlabelled = test_unlabelled.drop_duplicates(subset=['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_KYWilqyL93"
   },
   "outputs": [],
   "source": [
    "rs=42\n",
    "def strat_split(strat=False):\n",
    "  global rs\n",
    "  if strat:\n",
    "      from sklearn.model_selection import train_test_split      \n",
    "      X_train1, X_test1, y_train1, y_test1  = train_test_split(train.drop('mal', axis=1), train.mal, stratify=train.mal, test_size=0.29, random_state=rs )\n",
    "      X_train2, X_test2, y_train2, y_test2  = train_test_split(test_labelled.drop('mal', axis=1), test_labelled.mal, stratify=test_labelled.mal, test_size=0.29, random_state=rs)\n",
    "      X = np.concatenate((X_train1.comment_text, X_train2.comment_text))\n",
    "      y = np.concatenate((y_train1, y_train2))\n",
    "\n",
    "      X_test = np.concatenate((X_test1.comment_text, X_test2.comment_text))\n",
    "      y_test = np.concatenate((y_test1, y_test2))\n",
    "  else:\n",
    "      X = np.concatenate((train.comment_text, test_labelled.comment_text))\n",
    "      y = np.concatenate((train.mal, test_labelled.mal))\n",
    "      from sklearn.utils import shuffle\n",
    "      from sklearn.model_selection import train_test_split\n",
    "      X = shuffle(X, random_state=rs)\n",
    "      y = shuffle(y, random_state=rs)      \n",
    "      X, X_test, y, y_test  = train_test_split(X, y, stratify=y, test_size=0.3, random_state=rs )\n",
    "      \n",
    "  return X, X_test, y, y_test    \n",
    "X, X_test, y, y_test = strat_split(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kq6uloHZybm9"
   },
   "outputs": [],
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7805,
     "status": "ok",
     "timestamp": 1559807826393,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg",
      "userId": "01253993997636551956"
     },
     "user_tz": -120
    },
    "id": "yp3Sb225ylVj",
    "outputId": "9c4e9524-0e76-4937-82f7-f15e7eafb08f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=40000,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words='english', strip_accents='unicode',\n",
       "                sublinear_tf=True, token_pattern='\\\\w{1,}', tokenizer=None,\n",
       "                use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf  = StratifiedKFold(n_splits=5, random_state=rs)\n",
    "auc = []\n",
    "roc = []\n",
    "c   = 0\n",
    "\n",
    "word_vectorizer   = TfidfVectorizer(\n",
    "    sublinear_tf  = True,\n",
    "    strip_accents = 'unicode',\n",
    "    analyzer      = 'word',\n",
    "    token_pattern = r'\\w{1,}',\n",
    "    stop_words    = 'english',\n",
    "    ngram_range   = (1, 1),\n",
    "    max_features  = 40000)\n",
    "\n",
    "word_vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6uBKinv90SKh"
   },
   "outputs": [],
   "source": [
    "auc_pr = 0.093434375824395\n",
    "auc_roc = 0.02343524395\n",
    "c = 0\n",
    "C_parameter = np.arange(0.1, 1, 0.1) \n",
    "\n",
    "# use best C\n",
    "\n",
    "C_parameter = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dFQXRWY2ynsj"
   },
   "outputs": [],
   "source": [
    "for c_p in C_parameter:  \n",
    "      for c, (train_index, val_index) in enumerate(kf.split(X, y)):\n",
    "\n",
    "            X_train, X_val      = X[train_index], X[val_index]\n",
    "            y_train, y_val      = y[train_index], y[val_index] \n",
    "            train_word_features = word_vectorizer.transform(X_train)\n",
    "            val_word_features   = word_vectorizer.transform(X_val)\n",
    "            y_train             = y_train.astype('int')\n",
    "            y_val               = y_val.astype('int')\n",
    "            classifier          = LogisticRegression(C=c_p, solver='sag')\n",
    "            classifier.fit(train_word_features, y_train)\n",
    "            probs               = classifier.predict_proba(val_word_features)[:,1]\n",
    "            auc_roc             = roc_auc_score(y_val, probs)\n",
    "            auc_pr              = average_precision_score(y_val, probs)\n",
    "\n",
    "            if len(C_parameter)==1:\n",
    "                # print performance\n",
    "                print(f'---------------------------------------------')\n",
    "                print(f'FOLD {c}: AUC PR-C = {round(auc_pr, 4)}, AUC ROC = {round(auc_roc, 4)}')\n",
    "                print(f'---------------------------------------------')\n",
    "                print(f'')\n",
    "\n",
    "            auc.append(auc_pr)\n",
    "            roc.append(auc_roc)\n",
    "            c += 1\n",
    "\n",
    "      if len(C_parameter)!=1:\n",
    "             print(f'PARAMETER C = {c_p}')\n",
    "\n",
    "      # print performance\n",
    "      print(f'-----------------------------------------------')\n",
    "      print(f'CV average: AUC PR-C = {round(np.array(auc).mean(), 4)}, AUC ROC = {round(np.array(roc).mean(), 4)}')\n",
    "      print(f'-----------------------------------------------')\n",
    "      print(f'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3-gRY_RS_xDE"
   },
   "outputs": [],
   "source": [
    "# TRAIN ON WHOLE DAATA AND PREDICT ON TEST\n",
    "word_vectorizer.fit(X)\n",
    "train_word_features  = word_vectorizer.transform(X)\n",
    "test_word_features   = word_vectorizer.transform(X_test)\n",
    "classifier           = LogisticRegression(C=1, solver='sag')\n",
    "classifier.fit(train_word_features, y)\n",
    "probs                = classifier.predict_proba(test_word_features)[:,1]\n",
    "auc_roc              = roc_auc_score(y_test, probs)\n",
    "auc_pr               = average_precision_score(y_test, probs)\n",
    "\n",
    "# print performance\n",
    "print(f'-----------------------------------------')\n",
    "print(f'TEST: AUC PR-C = {round(auc_pr, 4)}, AUC ROC = {round(auc_roc, 4)}')\n",
    "print(f'-----------------------------------------')\n",
    "print(f'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u8Ow8Zl0BVpu"
   },
   "outputs": [],
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7492,
     "status": "ok",
     "timestamp": 1559812444872,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg",
      "userId": "01253993997636551956"
     },
     "user_tz": -120
    },
    "id": "JZh0JwvnEJAj",
    "outputId": "0991bb2b-5136-40f2-e4b9-e6b4ff23741a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=40000,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words='english', strip_accents='unicode',\n",
       "                sublinear_tf=True, token_pattern='\\\\w{1,}', tokenizer=None,\n",
       "                use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf  = StratifiedKFold(n_splits=5, random_state=rs)\n",
    "auc = []\n",
    "roc = []\n",
    "c   = 0\n",
    "\n",
    "word_vectorizer   = TfidfVectorizer(\n",
    "    sublinear_tf  = True,\n",
    "    strip_accents = 'unicode',\n",
    "    analyzer      = 'word',\n",
    "    token_pattern = r'\\w{1,}',\n",
    "    stop_words    = 'english',\n",
    "    ngram_range   = (1, 1),\n",
    "    max_features  = 40000)\n",
    "\n",
    "word_vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9255485,
     "status": "error",
     "timestamp": 1559829889747,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg",
      "userId": "01253993997636551956"
     },
     "user_tz": -120
    },
    "id": "gdaNEnbwEPVQ",
    "outputId": "2655721b-5bfa-4ffe-d79c-8cea6ca4c5e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=20)]: Done 160 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=20)]: Done 410 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=20)]: Done 600 out of 600 | elapsed:  4.2min finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 160 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done 410 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=20)]: Done 600 out of 600 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "FOLD 0: AUC PR-C = 0.8463, AUC ROC = 0.9595\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=20)]: Done 160 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=20)]: Done 410 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=20)]: Done 600 out of 600 | elapsed:  4.1min finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 160 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done 410 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=20)]: Done 600 out of 600 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "FOLD 1: AUC PR-C = 0.8541, AUC ROC = 0.9641\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=20)]: Done 160 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=20)]: Done 410 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=20)]: Done 600 out of 600 | elapsed:  3.9min finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 160 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=20)]: Done 410 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=20)]: Done 600 out of 600 | elapsed:    3.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "FOLD 2: AUC PR-C = 0.8481, AUC ROC = 0.9617\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=20)]: Done 160 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=20)]: Done 410 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=20)]: Done 600 out of 600 | elapsed:  3.6min finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 160 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done 410 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=20)]: Done 600 out of 600 | elapsed:    3.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "FOLD 3: AUC PR-C = 0.7881, AUC ROC = 0.9608\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=20)]: Done 160 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=20)]: Done 410 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=20)]: Done 600 out of 600 | elapsed:  3.6min finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 160 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=20)]: Done 410 tasks      | elapsed:    2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "FOLD 4: AUC PR-C = 0.7394, AUC ROC = 0.9615\n",
      "---------------------------------------------\n",
      "\n",
      "-----------------------------------------------\n",
      "CV average: AUC PR-C = 0.8152, AUC ROC = 0.9615\n",
      "-----------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done 600 out of 600 | elapsed:    3.4s finished\n"
     ]
    }
   ],
   "source": [
    "for c, (train_index, val_index) in enumerate(kf.split(X, y)):\n",
    "\n",
    "            X_train, X_val      = X[train_index], X[val_index]\n",
    "            y_train, y_val      = y[train_index], y[val_index] \n",
    "            train_word_features = word_vectorizer.transform(X_train)\n",
    "            val_word_features   = word_vectorizer.transform(X_val)\n",
    "            y_train             = y_train.astype('int')\n",
    "            y_val               = y_val.astype('int')\n",
    "            classifier          = RandomForestClassifier(n_estimators=600, max_depth=None, max_features='auto', \n",
    "                                    min_samples_split=2, verbose = True, n_jobs=20)\n",
    "            classifier.fit(train_word_features, y_train)\n",
    "            probs               = classifier.predict_proba(val_word_features)[:,1]\n",
    "            auc_roc             = roc_auc_score(y_val, probs)\n",
    "            auc_pr              = average_precision_score(y_val, probs)\n",
    "\n",
    "            \n",
    "            # print performance\n",
    "            print(f'---------------------------------------------')\n",
    "            print(f'FOLD {c}: AUC PR-C = {round(auc_pr, 4)}, AUC ROC = {round(auc_roc, 4)}')\n",
    "            print(f'---------------------------------------------')\n",
    "            print(f'')\n",
    "\n",
    "            auc.append(auc_pr)\n",
    "            roc.append(auc_roc)\n",
    "            c += 1\n",
    "\n",
    "\n",
    "# print performance\n",
    "print(f'-----------------------------------------------')\n",
    "print(f'CV average: AUC PR-C = {round(np.array(auc).mean(), 4)}, AUC ROC = {round(np.array(roc).mean(), 4)}')\n",
    "print(f'-----------------------------------------------')\n",
    "print(f'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=20)]: Done 160 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=20)]: Done 410 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=20)]: Done 600 out of 600 | elapsed:  4.5min finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=20)]: Done 160 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=20)]: Done 410 tasks      | elapsed:    7.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "TEST: AUC PR-C = 0.8144, AUC ROC = 0.9627\n",
      "-----------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done 600 out of 600 | elapsed:   11.5s finished\n"
     ]
    }
   ],
   "source": [
    "# TRAIN ON WHOLE DAATA AND PREDICT ON TEST\n",
    "word_vectorizer.fit(X)\n",
    "train_word_features  = word_vectorizer.transform(X)\n",
    "test_word_features   = word_vectorizer.transform(X_test)\n",
    "classifier           = RandomForestClassifier(n_estimators=600, max_depth=None, max_features='auto', \n",
    "                                    min_samples_split=2, verbose = True, n_jobs=20)\n",
    "classifier.fit(train_word_features, y)\n",
    "probs                = classifier.predict_proba(test_word_features)[:,1]\n",
    "auc_roc              = roc_auc_score(y_test, probs)\n",
    "auc_pr               = average_precision_score(y_test, probs)\n",
    "\n",
    "# print performance\n",
    "print(f'-----------------------------------------')\n",
    "print(f'TEST: AUC PR-C = {round(auc_pr, 4)}, AUC ROC = {round(auc_roc, 4)}')\n",
    "print(f'-----------------------------------------')\n",
    "print(f'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "penalty l1\n",
      "alpha 1e-05\n",
      "max_iter 1000\n",
      "-------------\n",
      "---------------------------------------------\n",
      "FOLD 0: AUC PR-C = 0.8622, AUC ROC = 0.9638\n",
      "---------------------------------------------\n",
      "\n",
      "---------------------------------------------\n",
      "FOLD 1: AUC PR-C = 0.8614, AUC ROC = 0.9623\n",
      "---------------------------------------------\n",
      "\n",
      "---------------------------------------------\n",
      "FOLD 2: AUC PR-C = 0.8645, AUC ROC = 0.9633\n",
      "---------------------------------------------\n",
      "\n",
      "---------------------------------------------\n",
      "FOLD 3: AUC PR-C = 0.8112, AUC ROC = 0.9626\n",
      "---------------------------------------------\n",
      "\n",
      "---------------------------------------------\n",
      "FOLD 4: AUC PR-C = 0.7806, AUC ROC = 0.9626\n",
      "---------------------------------------------\n",
      "\n",
      "-----------------------------------------------\n",
      "CV average: AUC PR-C = 0.836, AUC ROC = 0.963\n",
      "-----------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "penalty = ['l2', 'l1']\n",
    "alpha = [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "max_iter = [1000, 10000, 15000]\n",
    "\n",
    "# best parameters\n",
    "penalty = ['l1']\n",
    "alpha = [0.00001]\n",
    "max_iter = [1000] \n",
    "\n",
    "for p in penalty:\n",
    "  for a in alpha:\n",
    "    for i in max_iter:\n",
    "      auc = []\n",
    "      roc = []\n",
    "      c = 0\n",
    "      # print performance\n",
    "      print(f'-------------')\n",
    "      print(f'penalty {p}')\n",
    "      print(f'alpha {a}')\n",
    "      print(f'max_iter {i}')\n",
    "      print(f'-------------')\n",
    "      \n",
    "      for c, (train_index, val_index) in enumerate(kf.split(X, y)):\n",
    "\n",
    "            X_train, X_val      = X[train_index], X[val_index]\n",
    "            y_train, y_val      = y[train_index], y[val_index] \n",
    "            train_word_features = word_vectorizer.transform(X_train)\n",
    "            val_word_features   = word_vectorizer.transform(X_val)\n",
    "            y_train             = y_train.astype('int')\n",
    "            y_val               = y_val.astype('int')\n",
    "            classifier          = SGDClassifier(n_jobs=20, random_state=rs, loss='log', shuffle=False, \n",
    "                                    penalty=p, alpha=a, max_iter=i)\n",
    "            classifier.fit(train_word_features, y_train)\n",
    "            probs               = classifier.predict_proba(val_word_features)[:,1]\n",
    "            auc_roc             = roc_auc_score(y_val, probs)\n",
    "            auc_pr              = average_precision_score(y_val, probs)\n",
    "            \n",
    "            \n",
    "            print(f'---------------------------------------------')\n",
    "            print(f'FOLD {c}: AUC PR-C = {round(auc_pr, 4)}, AUC ROC = {round(auc_roc, 4)}')\n",
    "            print(f'---------------------------------------------')\n",
    "            print(f'')\n",
    "\n",
    "            auc.append(auc_pr)\n",
    "            roc.append(auc_roc)\n",
    "            c += 1\n",
    "\n",
    "\n",
    "# print performance\n",
    "print(f'-----------------------------------------------')\n",
    "print(f'CV average: AUC PR-C = {round(np.array(auc).mean(), 4)}, AUC ROC = {round(np.array(roc).mean(), 4)}')\n",
    "print(f'-----------------------------------------------')\n",
    "print(f'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "TEST: AUC PR-C = 0.827, AUC ROC = 0.9618\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAIN ON WHOLE DAATA AND PREDICT ON TEST\n",
    "word_vectorizer.fit(X)\n",
    "train_word_features  = word_vectorizer.transform(X)\n",
    "test_word_features   = word_vectorizer.transform(X_test)\n",
    "classifier           = SGDClassifier(n_jobs=20, random_state=rs, loss='log', shuffle=False, \n",
    "                                    penalty=penalty[0], alpha=alpha[0], max_iter=max_iter[0])\n",
    "classifier.fit(train_word_features, y)\n",
    "probs                = classifier.predict_proba(test_word_features)[:,1]\n",
    "auc_roc              = roc_auc_score(y_test, probs)\n",
    "auc_pr               = average_precision_score(y_test, probs)\n",
    "\n",
    "# print performance\n",
    "print(f'-----------------------------------------')\n",
    "print(f'TEST: AUC PR-C = {round(auc_pr, 4)}, AUC ROC = {round(auc_roc, 4)}')\n",
    "print(f'-----------------------------------------')\n",
    "print(f'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# muner of rounds\n",
    "max_rounds = 600\n",
    "stopping   = 600\n",
    "verbose    = 200\n",
    "\n",
    "# LGB parameters\n",
    "lgb_params = {\n",
    "    'boosting_type':     'gbdt',\n",
    "    'objective':         'binary',\n",
    "    'metrics':           'binary_logloss',\n",
    "    'bagging_fraction':  0.9,\n",
    "    'feature_fraction':  0.8,\n",
    "    'lambda_l1':         0.1,\n",
    "    'lambda_l2':         0.1,\n",
    "    'min_split_gain':    0.01,\n",
    "    'min_child_weight':  2,\n",
    "    'min_child_samples': 20,\n",
    "    'silent':            True,\n",
    "    'verbosity':         100,\n",
    "    'learning_rate':     0.1,\n",
    "    'max_depth':         7,\n",
    "    'num_leaves':        70,\n",
    "    'scale_pos_weight':  1,\n",
    "    'n_estimators':      max_rounds,\n",
    "    'nthread' :          20,\n",
    "    'random_state':      rs,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "FOLD 0: AUC PR-C = 0.8498, AUC ROC = 0.9587\n",
      "---------------------------------------------\n",
      "\n",
      "---------------------------------------------\n",
      "FOLD 1: AUC PR-C = 0.8542, AUC ROC = 0.9589\n",
      "---------------------------------------------\n",
      "\n",
      "---------------------------------------------\n",
      "FOLD 2: AUC PR-C = 0.8488, AUC ROC = 0.9569\n",
      "---------------------------------------------\n",
      "\n",
      "---------------------------------------------\n",
      "FOLD 3: AUC PR-C = 0.7982, AUC ROC = 0.9564\n",
      "---------------------------------------------\n",
      "\n",
      "---------------------------------------------\n",
      "FOLD 4: AUC PR-C = 0.7647, AUC ROC = 0.9575\n",
      "---------------------------------------------\n",
      "\n",
      "-----------------------------------------------\n",
      "CV average: AUC PR-C = 0.8296, AUC ROC = 0.9603\n",
      "-----------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c, (train_index, val_index) in enumerate(kf.split(X, y)):\n",
    "\n",
    "            X_train, X_val      = X[train_index], X[val_index]\n",
    "            y_train, y_val      = y[train_index], y[val_index] \n",
    "            train_word_features = word_vectorizer.transform(X_train)\n",
    "            val_word_features   = word_vectorizer.transform(X_val)\n",
    "            y_train             = y_train.astype('int')\n",
    "            y_val               = y_val.astype('int')\n",
    "            classifier          = lgb.LGBMClassifier(**lgb_params) \n",
    "            classifier.fit(train_word_features, y_train)\n",
    "            probs               = classifier.predict_proba(val_word_features)[:,1]\n",
    "            auc_roc             = roc_auc_score(y_val, probs)\n",
    "            auc_pr              = average_precision_score(y_val, probs)\n",
    "\n",
    "            \n",
    "            # print performance\n",
    "            print(f'---------------------------------------------')\n",
    "            print(f'FOLD {c}: AUC PR-C = {round(auc_pr, 4)}, AUC ROC = {round(auc_roc, 4)}')\n",
    "            print(f'---------------------------------------------')\n",
    "            print(f'')\n",
    "\n",
    "            auc.append(auc_pr)\n",
    "            roc.append(auc_roc)\n",
    "            c += 1\n",
    "\n",
    "# print performance\n",
    "print(f'-----------------------------------------------')\n",
    "print(f'CV average: AUC PR-C = {round(np.array(auc).mean(), 4)}, AUC ROC = {round(np.array(roc).mean(), 4)}')\n",
    "print(f'-----------------------------------------------')\n",
    "print(f'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "TEST: AUC PR-C = 0.8189, AUC ROC = 0.9582\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAIN ON WHOLE DAATA AND PREDICT ON TEST\n",
    "word_vectorizer.fit(X)\n",
    "train_word_features  = word_vectorizer.transform(X)\n",
    "test_word_features   = word_vectorizer.transform(X_test)\n",
    "classifier           = lgb.LGBMClassifier(**lgb_params) \n",
    "classifier.fit(train_word_features, y)\n",
    "probs                = classifier.predict_proba(test_word_features)[:,1]\n",
    "auc_roc              = roc_auc_score(y_test, probs)\n",
    "auc_pr               = average_precision_score(y_test, probs)\n",
    "\n",
    "# print performance\n",
    "print(f'-----------------------------------------')\n",
    "print(f'TEST: AUC PR-C = {round(auc_pr, 4)}, AUC ROC = {round(auc_roc, 4)}')\n",
    "print(f'-----------------------------------------')\n",
    "print(f'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "code_2_TML_DL.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
