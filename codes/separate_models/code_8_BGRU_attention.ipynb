{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"code_8_BGRU_attention.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"SQoEzO-1eML0","colab_type":"code","outputId":"b3df218f-7651-42b2-e2f8-749711bd7775","executionInfo":{"status":"ok","timestamp":1563298797760,"user_tz":-120,"elapsed":3237,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split, KFold\n","import random\n","\n","from sklearn.model_selection import cross_validate\n","from sklearn.metrics import roc_auc_score, average_precision_score\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","from keras.preprocessing import text, sequence\n","from keras.layers import Embedding, SpatialDropout1D\n","from keras.models import Model, Sequential\n","from keras.layers import Dense, Embedding, Input\n","from keras.optimizers import RMSprop\n","import keras.backend as K\n","from keras.layers import Dense, Input, GRU, LSTM, Bidirectional, Dropout, CuDNNLSTM, CuDNNGRU, GlobalAveragePooling1D, GlobalMaxPool1D\n","from sklearn.metrics import average_precision_score, roc_auc_score\n","from sklearn.model_selection import StratifiedKFold\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras.engine.topology import Layer, InputSpec\n","from keras import initializers as initializers, regularizers, constraints\n","\n","from numpy.random import seed\n","from tensorflow import set_random_seed\n","import random as rn\n","import os"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qCeSyw_eCrx4","colab_type":"code","outputId":"14f539d4-791a-4f29-af9e-5e4ad14beb3d","executionInfo":{"status":"ok","timestamp":1563298822127,"user_tz":-120,"elapsed":27202,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["# GOOGLE COLAB SETUP\n","\n","# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nak1uhxiEK0R","colab_type":"code","colab":{}},"source":["#2. Get the file\n","data_path          = 'drive/My Drive/Colab Notebooks/adaptHAN/AOBDL_code/data'\n","codes_path         = 'drive/My Drive/Colab Notebooks/adaptHAN/AOBDL_code/codes'\n","cv_models_path     = 'drive/My Drive/Colab Notebooks/adaptHAN/AOBDL_code/cv_models'\n","models_path        = 'drive/My Drive/Colab Notebooks/adaptHAN/AOBDL_code/models'\n","\n","\n","#3. Read file as panda dataframe\n","train         = pd.read_csv(f'{data_path}/train_cleaned_no_punkt.csv') \n","test_labelled = pd.read_csv(f'{data_path}/test_labelled_cleaned_no_punkt.csv') \n","test_unlabelled = pd.read_csv(f'{data_path}/test_unlabelled_cleaned_no_punkt.csv') "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f3ZeAcM_eGpj","colab_type":"code","colab":{}},"source":["train['mal']         = train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) >= 1  \n","train.drop(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'], axis=1, inplace=True)\n","train.comment_text.fillna(\"empty\", inplace=True)\n","\n","test_labelled['mal'] = test_labelled[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) >= 1  \n","test_labelled.drop(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'], axis=1, inplace=True)\n","test_labelled.comment_text.fillna(\"empty\", inplace=True)\n","\n","test_unlabelled.comment_text.fillna(\"empty\", inplace=True)\n","\n","# CHANGE TRAIN AND TEST, MIX TO GET SIMILAR DISTRIBUTION\n","from sklearn.model_selection import train_test_split\n","rs=42\n","X_train1, X_test1, y_train1, y_test1  = train_test_split(train.drop('mal', axis=1), train.mal, stratify=train.mal, test_size=0.29, random_state=rs )\n","X_train2, X_test2, y_train2, y_test2  = train_test_split(test_labelled.drop('mal', axis=1), test_labelled.mal, stratify=test_labelled.mal, test_size=0.29, random_state=rs)\n","\n","X = np.concatenate((X_train1.comment_text, X_train2.comment_text))\n","y = np.concatenate((y_train1, y_train2))\n","\n","X_test = np.concatenate((X_test1.comment_text, X_test2.comment_text))\n","y_test = np.concatenate((y_test1, y_test2))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pWPSaXneFFZu","colab_type":"code","colab":{}},"source":["#X = train.comment_text\n","#y = train.mal\n","\n","max_features = 40000\n","maxlen       = 400\n","dropout_rate = 0.25\n","rs           = 42\n","epochs       = 4\n","batch_size   = 256\n","embed_dim    = 50\n","rec_units    = 150\n","\n","\n","\n","\n","seed(rs)\n","set_random_seed(rs)\n","rn.seed(rs)\n","\n","os.environ['PYTHONHASHSEED']=str(rs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4DPm1-btWNGB","colab_type":"code","colab":{}},"source":["def dot_product(x, kernel):\n","    if K.backend() == 'tensorflow':\n","        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n","    else:\n","        return K.dot(x, kernel)\n","\n","class AttentionWithContext(Layer):\n","    def __init__(self,\n","                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n","                 W_constraint=None, u_constraint=None, b_constraint=None,\n","                 bias=True, **kwargs):\n","\n","        self.supports_masking = True\n","        self.init = initializers.get('glorot_uniform')\n","\n","        self.W_regularizer = regularizers.get(W_regularizer)\n","        self.u_regularizer = regularizers.get(u_regularizer)\n","        self.b_regularizer = regularizers.get(b_regularizer)\n","\n","        self.W_constraint = constraints.get(W_constraint)\n","        self.u_constraint = constraints.get(u_constraint)\n","        self.b_constraint = constraints.get(b_constraint)\n","\n","        self.bias = bias\n","        super(AttentionWithContext, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 3\n","\n","        self.W = self.add_weight((input_shape[-1], input_shape[-1]),\n","                                 initializer=self.init,\n","                                 name='{}_W'.format(self.name),\n","                                 regularizer=self.W_regularizer,\n","                                 constraint=self.W_constraint)\n","        if self.bias:\n","            self.b = self.add_weight((input_shape[-1],),\n","                                     initializer='zero',\n","                                     name='{}_b'.format(self.name),\n","                                     regularizer=self.b_regularizer,\n","                                     constraint=self.b_constraint)\n","\n","        self.u = self.add_weight((input_shape[-1],),\n","                                 initializer=self.init,\n","                                 name='{}_u'.format(self.name),\n","                                 regularizer=self.u_regularizer,\n","                                 constraint=self.u_constraint)\n","\n","        super(AttentionWithContext, self).build(input_shape)\n","\n","    def compute_mask(self, input, input_mask=None):\n","        return None\n","\n","    def call(self, x, mask=None):\n","        uit = dot_product(x, self.W)\n","\n","        if self.bias:\n","            uit += self.b\n","\n","        uit = K.tanh(uit)\n","        ait = dot_product(uit, self.u)\n","\n","        a = K.exp(ait)\n","\n","        if mask is not None:\n","            # Cast the mask to floatX to avoid float64 upcasting in theano\n","            a *= K.cast(mask, K.floatx())\n","\n","        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n","\n","        a = K.expand_dims(a)\n","        weighted_input = x * a\n","        return K.sum(weighted_input, axis=1)\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape[0], input_shape[-1]\n","      \n","      \n","      \n","class AttLayer(Layer):\n","    def __init__(self, attention_dim):\n","        self.init = initializers.get('normal')\n","        self.supports_masking = True\n","        self.attention_dim = attention_dim\n","        super(AttLayer, self).__init__()\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 3\n","        self.W = K.variable(self.init((input_shape[-1], self.attention_dim)))\n","        self.b = K.variable(self.init((self.attention_dim, )))\n","        self.u = K.variable(self.init((self.attention_dim, 1)))\n","        self.trainable_weights = [self.W, self.b, self.u]\n","        super(AttLayer, self).build(input_shape)\n","\n","    def compute_mask(self, inputs, mask=None):\n","        return mask\n","\n","    def call(self, x, mask=None):\n","        # size of x :[batch_size, sel_len, attention_dim]\n","        # size of u :[batch_size, attention_dim]\n","        # uit = tanh(xW+b)\n","        uit = K.tanh(K.bias_add(K.dot(x, self.W), self.b))\n","        ait = K.dot(uit, self.u)\n","        ait = K.squeeze(ait, -1)\n","\n","        ait = K.exp(ait)\n","\n","        if mask is not None:\n","            # Cast the mask to floatX to avoid float64 upcasting in theano\n","            ait *= K.cast(mask, K.floatx())\n","        ait /= K.cast(K.sum(ait, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n","        ait = K.expand_dims(ait)\n","        weighted_input = x * ait\n","        output = K.sum(weighted_input, axis=1)\n","\n","        return output\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0], input_shape[-1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ac0ThFO3FIHI","colab_type":"code","colab":{}},"source":["def gru_keras(max_features, maxlen, dropout_rate, embed_dim, rec_units, reduction = 'average'):\n","    if K.backend == 'tensorflow':        \n","        K.clear_session()\n","    input_layer = Input(shape=(maxlen,))\n","    embedding_layer = Embedding(max_features, output_dim=embed_dim, trainable=True)(input_layer)\n","    x = SpatialDropout1D(dropout_rate)(embedding_layer)\n","    x = Bidirectional(CuDNNGRU(units=rec_units, return_sequences=True))(x)\n","    if reduction == 'average':\n","      x = GlobalAveragePooling1D()(x)\n","    elif reduction == 'maximum':\n","      x = GlobalMaxPool1D()(x)\n","    elif reduction == 'attention':\n","      x = AttentionWithContext()(x)\n","      \n","    output_layer = Dense(1, activation=\"sigmoid\")(x)\n","    model = Model(inputs=input_layer, outputs=output_layer)\n","    model.compile(loss='binary_crossentropy',\n","                  optimizer=RMSprop(clipvalue=1, clipnorm=1),\n","                  metrics=['acc'])\n","    #print( model.summary())\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BFgVXjNPF-dM","colab_type":"code","colab":{}},"source":["kf = StratifiedKFold(n_splits=5, random_state=rs)\n","auc = []\n","roc = []\n","c = 0\n","#tokenizer = text.Tokenizer(num_words=max_features)\n","#tokenizer.fit_on_texts(X)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jjvUHMVYj3qv","colab_type":"text"},"source":["### Average Pooling"]},{"cell_type":"code","metadata":{"id":"-49hvW4_GHww","colab_type":"code","outputId":"4d76bc24-9af3-4867-f8a9-cbc4efc8f378","executionInfo":{"status":"ok","timestamp":1563283049664,"user_tz":-120,"elapsed":302661,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["c=0\n","for train_index, val_index in kf.split(X, y):\n","    print(f' fold {c}')\n","    X_train, X_val       = X[train_index], X[val_index]\n","    y_train, y_val       = y[train_index], y[val_index] \n","    tokenizer = text.Tokenizer(num_words=max_features)\n","    tokenizer.fit_on_texts(X_train)\n","    list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n","    list_tokenized_val   = tokenizer.texts_to_sequences(X_val)\n","    X_train              = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n","    X_val                = sequence.pad_sequences(list_tokenized_val, maxlen=maxlen)\n","    model                = gru_keras(max_features, maxlen, dropout_rate, embed_dim, rec_units)\n","    print('Fitting')\n","    history              = model.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val), epochs=4, shuffle=True, verbose=1)\n","    probs                = model.predict(X_val, batch_size=batch_size, verbose=1)\n","    \n","    model.save_weights(f'{cv_models_path}/BGRU_avpool_fold_{c}.h5')\n","    \n","    auc_f                = average_precision_score(y_val, probs)\n","    auc.append(auc_f)\n","    roc_f                = roc_auc_score(y_val, probs)\n","    roc.append(roc_f)\n","    print(f' average precision {auc_f}')\n","    print(f' roc auc {roc_f}')\n","    c += 1\n","    del model"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" fold 0\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0716 12:26:42.481697 140713413273472 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0716 12:26:42.483678 140713413273472 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0716 12:26:42.488303 140713413273472 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0716 12:26:42.521610 140713413273472 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","W0716 12:26:42.532542 140713413273472 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","W0716 12:26:43.404370 140713413273472 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0716 12:26:43.413841 140713413273472 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","W0716 12:26:43.423357 140713413273472 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Fitting\n","Train on 126974 samples, validate on 31745 samples\n","Epoch 1/4\n","126974/126974 [==============================] - 147s 1ms/step - loss: 0.2419 - acc: 0.9178 - val_loss: 0.1361 - val_acc: 0.9513\n","Epoch 2/4\n","126974/126974 [==============================] - 146s 1ms/step - loss: 0.1286 - acc: 0.9507 - val_loss: 0.1045 - val_acc: 0.9625\n","Epoch 3/4\n","126974/126974 [==============================] - 145s 1ms/step - loss: 0.1148 - acc: 0.9554 - val_loss: 0.1051 - val_acc: 0.9617\n","Epoch 4/4\n","126974/126974 [==============================] - 145s 1ms/step - loss: 0.1100 - acc: 0.9572 - val_loss: 0.1065 - val_acc: 0.9614\n","31745/31745 [==============================] - 11s 339us/step\n"," average precision 0.8902162353081848\n"," roc auc 0.9761814946854341\n"," fold 1\n","Fitting\n","Train on 126974 samples, validate on 31745 samples\n","Epoch 1/4\n","126974/126974 [==============================] - 148s 1ms/step - loss: 0.2474 - acc: 0.9191 - val_loss: 0.1534 - val_acc: 0.9523\n","Epoch 2/4\n","126974/126974 [==============================] - 145s 1ms/step - loss: 0.1582 - acc: 0.9461 - val_loss: 0.1609 - val_acc: 0.9586\n","Epoch 3/4\n","126974/126974 [==============================] - 145s 1ms/step - loss: 0.1451 - acc: 0.9515 - val_loss: 0.1240 - val_acc: 0.9607\n","Epoch 4/4\n","126974/126974 [==============================] - 145s 1ms/step - loss: 0.1315 - acc: 0.9534 - val_loss: 0.1145 - val_acc: 0.9587\n","31745/31745 [==============================] - 11s 340us/step\n"," average precision 0.878989063677801\n"," roc auc 0.9707822508176243\n"," fold 2\n","Fitting\n","Train on 126976 samples, validate on 31743 samples\n","Epoch 1/4\n","126976/126976 [==============================] - 147s 1ms/step - loss: 0.2417 - acc: 0.9174 - val_loss: 0.1671 - val_acc: 0.9427\n","Epoch 2/4\n","126976/126976 [==============================] - 145s 1ms/step - loss: 0.1291 - acc: 0.9508 - val_loss: 0.1040 - val_acc: 0.9639\n","Epoch 3/4\n","126976/126976 [==============================] - 147s 1ms/step - loss: 0.1158 - acc: 0.9551 - val_loss: 0.1067 - val_acc: 0.9630\n","Epoch 4/4\n","126976/126976 [==============================] - 145s 1ms/step - loss: 0.1103 - acc: 0.9563 - val_loss: 0.1047 - val_acc: 0.9613\n","31743/31743 [==============================] - 11s 348us/step\n"," average precision 0.8952056885354828\n"," roc auc 0.9761166853874668\n"," fold 3\n","Fitting\n","Train on 126976 samples, validate on 31743 samples\n","Epoch 1/4\n","126976/126976 [==============================] - 146s 1ms/step - loss: 0.2418 - acc: 0.9166 - val_loss: 0.1560 - val_acc: 0.9394\n","Epoch 2/4\n","126976/126976 [==============================] - 146s 1ms/step - loss: 0.1247 - acc: 0.9537 - val_loss: 0.1304 - val_acc: 0.9467\n","Epoch 3/4\n","126976/126976 [==============================] - 146s 1ms/step - loss: 0.1097 - acc: 0.9579 - val_loss: 0.1258 - val_acc: 0.9502\n","Epoch 4/4\n","126976/126976 [==============================] - 146s 1ms/step - loss: 0.1050 - acc: 0.9594 - val_loss: 0.1232 - val_acc: 0.9505\n","31743/31743 [==============================] - 11s 348us/step\n"," average precision 0.8357154076726\n"," roc auc 0.9700720114944358\n"," fold 4\n","Fitting\n","Train on 126976 samples, validate on 31743 samples\n","Epoch 1/4\n","126976/126976 [==============================] - 147s 1ms/step - loss: 0.2333 - acc: 0.9254 - val_loss: 0.1909 - val_acc: 0.9201\n","Epoch 2/4\n","126976/126976 [==============================] - 145s 1ms/step - loss: 0.1764 - acc: 0.9434 - val_loss: 0.1897 - val_acc: 0.9237\n","Epoch 3/4\n","126976/126976 [==============================] - 144s 1ms/step - loss: 0.1222 - acc: 0.9596 - val_loss: 0.1506 - val_acc: 0.9355\n","Epoch 4/4\n","126976/126976 [==============================] - 146s 1ms/step - loss: 0.1160 - acc: 0.9611 - val_loss: 0.1401 - val_acc: 0.9420\n","31743/31743 [==============================] - 11s 349us/step\n"," average precision 0.7926180471590829\n"," roc auc 0.9663327297517558\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oD-G2cO9GLz3","colab_type":"code","colab":{}},"source":["data = pd.DataFrame({'acc':history.history['acc'],\n","                    'loss': history.history['loss'],\n","                    'val_acc': history.history['val_acc'],\n","                    'val_loss': history.history['val_loss']})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S51--4EBjMKx","colab_type":"code","outputId":"8976aabb-5d00-462b-91c3-42d4b786adf6","executionInfo":{"status":"ok","timestamp":1563283049676,"user_tz":-120,"elapsed":42,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["np.array(auc).mean()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8585488884706305"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"EPtxc1qPTfoC","colab_type":"code","outputId":"931e0242-be30-42d1-91a8-393c4e05eb1d","executionInfo":{"status":"ok","timestamp":1563283049678,"user_tz":-120,"elapsed":31,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["np.array(roc).mean()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9718970344273433"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"r0hIZHoGctiz","colab_type":"code","outputId":"6b70b093-1452-45d3-ebe8-3e812333c266","executionInfo":{"status":"ok","timestamp":1563306031459,"user_tz":-120,"elapsed":711747,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["X_train   = X\n","y_train   = y\n","tokenizer = text.Tokenizer(num_words=max_features, oov_token='unknown')\n","tokenizer.fit_on_texts(X_train)\n","\n","list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n","list_tokenized_test  = tokenizer.texts_to_sequences(X_test)\n","X_train = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n","X_test  = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen)\n","\n","model   = gru_keras(max_features, maxlen, dropout_rate, embed_dim, rec_units, reduction='average')\n","\n","y_train = np.array(y_train)\n","y_test  = np.array(y_test)\n","\n","print('Fitting')\n","model.fit(X_train, y_train,   batch_size=batch_size, epochs=epochs, shuffle=True, verbose=1)\n","probs = model.predict(X_test, batch_size=batch_size, verbose=1)\n","auc_f = average_precision_score(y_test, probs)\n","roc_f = roc_auc_score(y_test, probs)\n","model.save_weights(f'{models_path}/BGRU_avpool.h5')\n","del model"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Fitting\n","Epoch 1/4\n","158719/158719 [==============================] - 168s 1ms/step - loss: 0.2128 - acc: 0.9264\n","Epoch 2/4\n","158719/158719 [==============================] - 166s 1ms/step - loss: 0.1231 - acc: 0.9530\n","Epoch 3/4\n","158719/158719 [==============================] - 166s 1ms/step - loss: 0.1155 - acc: 0.9562\n","Epoch 4/4\n","158719/158719 [==============================] - 166s 1ms/step - loss: 0.1110 - acc: 0.9575\n","64830/64830 [==============================] - 23s 349us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gmjiSTh4PCSA","colab_type":"code","outputId":"51806742-6953-4cb4-fe91-dd48a352445a","executionInfo":{"status":"ok","timestamp":1563306031469,"user_tz":-120,"elapsed":705093,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["auc_f"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8551740293955945"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"k-ptNl8KDarn","colab_type":"code","outputId":"bb86e70f-806f-446f-efc8-7009966ff964","executionInfo":{"status":"ok","timestamp":1563306031473,"user_tz":-120,"elapsed":704793,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["roc_f"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9712122873957301"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"SpUknIrXj0lM","colab_type":"text"},"source":["### Maximum Pooling"]},{"cell_type":"code","metadata":{"id":"Tir9BE9Ul5Ps","colab_type":"code","outputId":"3f13be55-e9b8-48d3-e5b2-e604709de5cc","executionInfo":{"status":"ok","timestamp":1563286905903,"user_tz":-120,"elapsed":2183361,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["c=0 # added later, this is why model shows folds starting with 5\n","# MAXIMUM POOLING\n","for train_index, val_index in kf.split(X, y):\n","    print(f' fold {c}')\n","    X_train, X_val       = X[train_index], X[val_index]\n","    y_train, y_val       = y[train_index], y[val_index] \n","    tokenizer = text.Tokenizer(num_words=max_features)\n","    tokenizer.fit_on_texts(X_train)\n","    list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n","    list_tokenized_val   = tokenizer.texts_to_sequences(X_val)\n","    X_train              = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n","    X_val                = sequence.pad_sequences(list_tokenized_val, maxlen=maxlen)\n","    model                = gru_keras(max_features, maxlen, dropout_rate, embed_dim, rec_units, reduction='maximum')\n","    print('Fitting')\n","    history              = model.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val), epochs=4, shuffle=True, verbose=1)\n","    probs                = model.predict(X_val, batch_size=batch_size, verbose=1)\n","    \n","    model.save_weights(f'{cv_models_path}/BGRU_maxpool_fold_{c}.h5')\n","    \n","    auc_f                = average_precision_score(y_val, probs)\n","    auc.append(auc_f)\n","    roc_f                = roc_auc_score(y_val, probs)\n","    roc.append(roc_f)\n","    print(f' average precision {auc_f}')\n","    print(f' roc auc {roc_f}')\n","    c += 1\n","    del model"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" fold 0\n","Fitting\n","Train on 126974 samples, validate on 31745 samples\n","Epoch 1/4\n","126974/126974 [==============================] - 150s 1ms/step - loss: 0.1762 - acc: 0.9364 - val_loss: 0.1086 - val_acc: 0.9604\n","Epoch 2/4\n","126974/126974 [==============================] - 149s 1ms/step - loss: 0.1179 - acc: 0.9536 - val_loss: 0.1188 - val_acc: 0.9560\n","Epoch 3/4\n","126974/126974 [==============================] - 150s 1ms/step - loss: 0.1093 - acc: 0.9566 - val_loss: 0.1138 - val_acc: 0.9589\n","Epoch 4/4\n","126974/126974 [==============================] - 149s 1ms/step - loss: 0.1047 - acc: 0.9584 - val_loss: 0.1084 - val_acc: 0.9603\n","31745/31745 [==============================] - 11s 354us/step\n"," average precision 0.8872602875246838\n"," roc auc 0.9759753888605988\n"," fold 1\n","Fitting\n","Train on 126974 samples, validate on 31745 samples\n","Epoch 1/4\n","126974/126974 [==============================] - 150s 1ms/step - loss: 0.1721 - acc: 0.9368 - val_loss: 0.1172 - val_acc: 0.9570\n","Epoch 2/4\n","126974/126974 [==============================] - 149s 1ms/step - loss: 0.1166 - acc: 0.9545 - val_loss: 0.1047 - val_acc: 0.9614\n","Epoch 3/4\n","126974/126974 [==============================] - 149s 1ms/step - loss: 0.1099 - acc: 0.9565 - val_loss: 0.1051 - val_acc: 0.9625\n","Epoch 4/4\n","126974/126974 [==============================] - 149s 1ms/step - loss: 0.1050 - acc: 0.9583 - val_loss: 0.1109 - val_acc: 0.9608\n","31745/31745 [==============================] - 11s 355us/step\n"," average precision 0.8833742927713171\n"," roc auc 0.9733072680446009\n"," fold 2\n","Fitting\n","Train on 126976 samples, validate on 31743 samples\n","Epoch 1/4\n","126976/126976 [==============================] - 151s 1ms/step - loss: 0.1777 - acc: 0.9353 - val_loss: 0.1127 - val_acc: 0.9589\n","Epoch 2/4\n","126976/126976 [==============================] - 149s 1ms/step - loss: 0.1182 - acc: 0.9537 - val_loss: 0.1249 - val_acc: 0.9537\n","Epoch 3/4\n","126976/126976 [==============================] - 149s 1ms/step - loss: 0.1114 - acc: 0.9561 - val_loss: 0.1169 - val_acc: 0.9573\n","Epoch 4/4\n","126976/126976 [==============================] - 149s 1ms/step - loss: 0.1067 - acc: 0.9582 - val_loss: 0.1031 - val_acc: 0.9630\n","31743/31743 [==============================] - 11s 357us/step\n"," average precision 0.8888119748182979\n"," roc auc 0.9748323554272443\n"," fold 3\n","Fitting\n","Train on 126976 samples, validate on 31743 samples\n","Epoch 1/4\n","126976/126976 [==============================] - 150s 1ms/step - loss: 0.1728 - acc: 0.9392 - val_loss: 0.1409 - val_acc: 0.9449\n","Epoch 2/4\n","126976/126976 [==============================] - 147s 1ms/step - loss: 0.1123 - acc: 0.9570 - val_loss: 0.1251 - val_acc: 0.9504\n","Epoch 3/4\n","126976/126976 [==============================] - 148s 1ms/step - loss: 0.1036 - acc: 0.9595 - val_loss: 0.1257 - val_acc: 0.9502\n","Epoch 4/4\n","126976/126976 [==============================] - 149s 1ms/step - loss: 0.0988 - acc: 0.9614 - val_loss: 0.1327 - val_acc: 0.9462\n","31743/31743 [==============================] - 11s 360us/step\n"," average precision 0.8339553071736594\n"," roc auc 0.9690821018428359\n"," fold 4\n","Fitting\n","Train on 126976 samples, validate on 31743 samples\n","Epoch 1/4\n","126976/126976 [==============================] - 152s 1ms/step - loss: 0.1698 - acc: 0.9412 - val_loss: 0.1978 - val_acc: 0.9178\n","Epoch 2/4\n","126976/126976 [==============================] - 150s 1ms/step - loss: 0.1058 - acc: 0.9605 - val_loss: 0.1475 - val_acc: 0.9372\n","Epoch 3/4\n","126976/126976 [==============================] - 149s 1ms/step - loss: 0.0990 - acc: 0.9622 - val_loss: 0.1556 - val_acc: 0.9322\n","Epoch 4/4\n","126976/126976 [==============================] - 149s 1ms/step - loss: 0.0954 - acc: 0.9631 - val_loss: 0.1733 - val_acc: 0.9263\n","31743/31743 [==============================] - 11s 362us/step\n"," average precision 0.8032888148718693\n"," roc auc 0.9695281403213536\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PJk3FwJ1jdEr","colab_type":"code","outputId":"f3ce31db-83ee-4566-9d5e-ab344d99eb56","executionInfo":{"status":"ok","timestamp":1563286905907,"user_tz":-120,"elapsed":53,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["np.array(auc).mean()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8589435119512979"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"XDvEj-CAjd90","colab_type":"code","outputId":"735647b0-5c3d-4db1-c59d-64bef9048d72","executionInfo":{"status":"ok","timestamp":1563286905914,"user_tz":-120,"elapsed":36,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["np.array(roc).mean()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.972221042663335"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"Yr41POAKjhIK","colab_type":"code","outputId":"9ec5ee23-ccc0-47ad-a212-130eee31a277","executionInfo":{"status":"ok","timestamp":1563287721358,"user_tz":-120,"elapsed":594,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["X_train = X\n","y_train = y\n","\n","tokenizer            = text.Tokenizer(num_words=max_features, oov_token='unknown')\n","tokenizer.fit_on_texts(X_train)\n","\n","list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n","#list_tokenized_test  = tokenizer.texts_to_sequences(X_test)\n","X_train = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n","X_test = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen)\n","\n","model = gru_keras(max_features, maxlen, dropout_rate, embed_dim, rec_units, reduction='maximum')\n","\n","y_train              = np.array(y_train)\n","y_test               = np.array(y_test)\n","\n","print('Fitting')\n","model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, shuffle=True, verbose=1)\n","probs = model.predict(X_test, batch_size=batch_size, verbose=1)\n","auc_f = average_precision_score(y_test, probs)\n","roc_f = roc_auc_score(y_test, probs)\n","model.save_weights(f'{models_path}/BGRU_maxpool.h5')\n","del model"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Fitting\n","Epoch 1/4\n","158719/158719 [==============================] - 175s 1ms/step - loss: 0.1645 - acc: 0.9409\n","Epoch 2/4\n","158719/158719 [==============================] - 173s 1ms/step - loss: 0.1135 - acc: 0.9555\n","Epoch 3/4\n","158719/158719 [==============================] - 172s 1ms/step - loss: 0.1067 - acc: 0.9578\n","Epoch 4/4\n","158719/158719 [==============================] - 172s 1ms/step - loss: 0.1024 - acc: 0.9598\n","64830/64830 [==============================] - 22s 345us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mONuOlIjji8l","colab_type":"code","outputId":"d0f8877c-e759-4e0e-8aae-1524d4d0df66","executionInfo":{"status":"ok","timestamp":1563287721359,"user_tz":-120,"elapsed":54,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["auc_f"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8572895918138027"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"bhvFWULljkhr","colab_type":"code","outputId":"71effe1d-25a6-4f08-b7d1-0739092eedb8","executionInfo":{"status":"ok","timestamp":1563287721362,"user_tz":-120,"elapsed":33,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["roc_f"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9718163984283306"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"rJ5af49qjmpW","colab_type":"text"},"source":["### ATTENTION"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jkDiySu6jwj9","outputId":"55b426ac-0c75-48d6-e0d0-a298973ba88b","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1563302511873,"user_tz":-120,"elapsed":3679353,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}}},"source":["c = 0\n","for train_index, val_index in kf.split(X, y):\n","    print(f' fold {c}')\n","    X_train, X_val       = X[train_index], X[val_index]\n","    y_train, y_val       = y[train_index], y[val_index] \n","    tokenizer = text.Tokenizer(num_words=max_features)\n","    tokenizer.fit_on_texts(X_train)\n","    list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n","    list_tokenized_val   = tokenizer.texts_to_sequences(X_val)\n","    X_train              = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n","    X_val                = sequence.pad_sequences(list_tokenized_val, maxlen=maxlen)\n","    model                = gru_keras(max_features, maxlen, dropout_rate, embed_dim, rec_units, reduction='attention')\n","    print('Fitting')\n","    history              = model.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val), epochs=4, shuffle=True, verbose=1)\n","    probs                = model.predict(X_val, batch_size=batch_size, verbose=1)\n","    \n","    model.save_weights(f'{cv_models_path}/BGRU_attention_fold_{c}.h5')\n","    \n","    auc_f                = average_precision_score(y_val, probs)\n","    auc.append(auc_f)\n","    roc_f                = roc_auc_score(y_val, probs)\n","    roc.append(roc_f)\n","    print(f' average precision {auc_f}')\n","    print(f' roc auc {roc_f}')\n","    c += 1\n","    del model"],"execution_count":10,"outputs":[{"output_type":"stream","text":[" fold 0\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0716 17:40:51.572584 140219485386624 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0716 17:40:51.575054 140219485386624 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0716 17:40:51.589144 140219485386624 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0716 17:40:51.623919 140219485386624 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","W0716 17:40:51.638307 140219485386624 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","W0716 17:40:53.840707 140219485386624 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0716 17:40:53.853206 140219485386624 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","W0716 17:40:53.862703 140219485386624 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Fitting\n","Train on 126974 samples, validate on 31745 samples\n","Epoch 1/4\n","126974/126974 [==============================] - 183s 1ms/step - loss: 0.2446 - acc: 0.9196 - val_loss: 0.1609 - val_acc: 0.9494\n","Epoch 2/4\n","126974/126974 [==============================] - 175s 1ms/step - loss: 0.1506 - acc: 0.9463 - val_loss: 0.1295 - val_acc: 0.9540\n","Epoch 3/4\n","126974/126974 [==============================] - 176s 1ms/step - loss: 0.1253 - acc: 0.9527 - val_loss: 0.1085 - val_acc: 0.9604\n","Epoch 4/4\n","126974/126974 [==============================] - 175s 1ms/step - loss: 0.1205 - acc: 0.9533 - val_loss: 0.1122 - val_acc: 0.9607\n","31745/31745 [==============================] - 13s 414us/step\n"," average precision 0.8873648429893102\n"," roc auc 0.9719721211073193\n"," fold 1\n","Fitting\n","Train on 126974 samples, validate on 31745 samples\n","Epoch 1/4\n","126974/126974 [==============================] - 177s 1ms/step - loss: 0.2442 - acc: 0.9211 - val_loss: 0.1722 - val_acc: 0.9548\n","Epoch 2/4\n","126974/126974 [==============================] - 176s 1ms/step - loss: 0.1758 - acc: 0.9475 - val_loss: 0.1514 - val_acc: 0.9548\n","Epoch 3/4\n","126974/126974 [==============================] - 176s 1ms/step - loss: 0.1409 - acc: 0.9492 - val_loss: 0.1388 - val_acc: 0.9488\n","Epoch 4/4\n","126974/126974 [==============================] - 176s 1ms/step - loss: 0.1268 - acc: 0.9511 - val_loss: 0.1338 - val_acc: 0.9525\n","31745/31745 [==============================] - 13s 416us/step\n"," average precision 0.8784571459622889\n"," roc auc 0.9693565542859552\n"," fold 2\n","Fitting\n","Train on 126976 samples, validate on 31743 samples\n","Epoch 1/4\n","126976/126976 [==============================] - 176s 1ms/step - loss: 0.2423 - acc: 0.9185 - val_loss: 0.1586 - val_acc: 0.9539\n","Epoch 2/4\n","126976/126976 [==============================] - 175s 1ms/step - loss: 0.1504 - acc: 0.9466 - val_loss: 0.1282 - val_acc: 0.9606\n","Epoch 3/4\n","126976/126976 [==============================] - 174s 1ms/step - loss: 0.1279 - acc: 0.9507 - val_loss: 0.1152 - val_acc: 0.9614\n","Epoch 4/4\n","126976/126976 [==============================] - 173s 1ms/step - loss: 0.1185 - acc: 0.9547 - val_loss: 0.1228 - val_acc: 0.9552\n","31743/31743 [==============================] - 13s 420us/step\n"," average precision 0.8768343576213421\n"," roc auc 0.9710741186686103\n"," fold 3\n","Fitting\n","Train on 126976 samples, validate on 31743 samples\n","Epoch 1/4\n","126976/126976 [==============================] - 176s 1ms/step - loss: 0.2442 - acc: 0.9193 - val_loss: 0.1622 - val_acc: 0.9376\n","Epoch 2/4\n","126976/126976 [==============================] - 174s 1ms/step - loss: 0.1592 - acc: 0.9426 - val_loss: 0.1492 - val_acc: 0.9440\n","Epoch 3/4\n","126976/126976 [==============================] - 174s 1ms/step - loss: 0.1255 - acc: 0.9526 - val_loss: 0.1390 - val_acc: 0.9453\n","Epoch 4/4\n","126976/126976 [==============================] - 174s 1ms/step - loss: 0.1122 - acc: 0.9570 - val_loss: 0.1321 - val_acc: 0.9475\n","31743/31743 [==============================] - 13s 422us/step\n"," average precision 0.8216724930593537\n"," roc auc 0.9679334652041789\n"," fold 4\n","Fitting\n","Train on 126976 samples, validate on 31743 samples\n","Epoch 1/4\n","126976/126976 [==============================] - 176s 1ms/step - loss: 0.2292 - acc: 0.9236 - val_loss: 0.1712 - val_acc: 0.9302\n","Epoch 2/4\n","126976/126976 [==============================] - 173s 1ms/step - loss: 0.1362 - acc: 0.9507 - val_loss: 0.1631 - val_acc: 0.9294\n","Epoch 3/4\n","126976/126976 [==============================] - 173s 1ms/step - loss: 0.1070 - acc: 0.9603 - val_loss: 0.1481 - val_acc: 0.9376\n","Epoch 4/4\n","126976/126976 [==============================] - 173s 1ms/step - loss: 0.1055 - acc: 0.9607 - val_loss: 0.1523 - val_acc: 0.9359\n","31743/31743 [==============================] - 13s 423us/step\n"," average precision 0.7923343564748064\n"," roc auc 0.9678156674377858\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"I6CuyhSAjwkB","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"454f1a5e-c5e2-421b-fdb8-1eda8b895b1d","executionInfo":{"status":"ok","timestamp":1563302511888,"user_tz":-120,"elapsed":3676121,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}}},"source":["np.array(auc).mean()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8513326392214203"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xvOwVZTBjwkC","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"f422c9be-1080-4edb-b9fc-6f296cda13fb","executionInfo":{"status":"ok","timestamp":1563302511890,"user_tz":-120,"elapsed":3675600,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}}},"source":["np.array(roc).mean()"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9696303853407698"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9D1-IzxJjwkE","colab":{"base_uri":"https://localhost:8080/","height":207},"outputId":"255a7742-ebbe-40b9-85a6-322f265b4730","executionInfo":{"status":"ok","timestamp":1563303375234,"user_tz":-120,"elapsed":4536182,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}}},"source":["X_train = X\n","y_train = y\n","\n","tokenizer            = text.Tokenizer(num_words=max_features, oov_token='unknown')\n","tokenizer.fit_on_texts(X_train)\n","\n","list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n","#list_tokenized_test  = tokenizer.texts_to_sequences(X_test)\n","X_train = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n","X_test = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen)\n","\n","model = gru_keras(max_features, maxlen, dropout_rate, embed_dim, rec_units, reduction='attention')\n","\n","y_train              = np.array(y_train)\n","y_test               = np.array(y_test)\n","\n","print('Fitting')\n","model.fit(X_train, y_train, batch_size=batch_size, epochs=4, shuffle=True, verbose=1)\n","probs = model.predict(X_test, batch_size=batch_size, verbose=1)\n","\n","model.save_weights(f'{models_path}/BGRU_attention.h5')\n","\n","auc_f = average_precision_score(y_test, probs)\n","roc_f = roc_auc_score(y_test, probs)\n","del model"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Fitting\n","Epoch 1/4\n","158719/158719 [==============================] - 203s 1ms/step - loss: 0.2007 - acc: 0.9310\n","Epoch 2/4\n","158719/158719 [==============================] - 202s 1ms/step - loss: 0.1304 - acc: 0.9516\n","Epoch 3/4\n","158719/158719 [==============================] - 202s 1ms/step - loss: 0.1141 - acc: 0.9562\n","Epoch 4/4\n","158719/158719 [==============================] - 202s 1ms/step - loss: 0.1085 - acc: 0.9581\n","64830/64830 [==============================] - 27s 419us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"voxjlSrEjwkF","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b4aa1b83-ea7e-4516-8817-620b9860ffb5","executionInfo":{"status":"ok","timestamp":1563303375236,"user_tz":-120,"elapsed":4534608,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}}},"source":["auc_f"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8560058462711782"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"A9LzdPIAjwkG","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b77a7d4e-40d6-4852-fc39-4b607f9eee15","executionInfo":{"status":"ok","timestamp":1563303375237,"user_tz":-120,"elapsed":4534159,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}}},"source":["roc_f"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.971687733054089"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"cFKdvFaWmqQU","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}